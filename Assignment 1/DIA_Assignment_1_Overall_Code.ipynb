{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngd_tARCOoui",
    "outputId": "3691724c-41ca-4f7a-ae17-7218f932419c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img_bgr = cv2.imread('image2.jpg') #Image is being read in BGR color palette\n",
    "img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KA-Ubpa4Reah",
    "outputId": "bda0148b-559e-4425-fa52-c92f85a71e09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "[162 215 255]\n",
      "[[ 0.33333333  0.33333333  0.33333333]\n",
      " [-0.40824829 -0.40824829  0.81649658]\n",
      " [ 0.40824829 -0.81649658  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#1.1.1 Shadow-Map Generation\n",
    "\n",
    "#RGB to HSI\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "img_np = np.asarray(img)\n",
    "print(img_np.shape)\n",
    "\n",
    "h, w, c = img_np.shape\n",
    "\n",
    "I = np.zeros((h, w, 1))\n",
    "V1 = np.zeros((h, w, 1))\n",
    "V2 = np.zeros((h, w, 1))\n",
    "S = np.zeros((h, w, 1))\n",
    "H = np.zeros((h, w, 1))\n",
    "\n",
    "print(img[0][0])\n",
    "\n",
    "hsi_mat = np.array([[1/3, 1/3, 1/3], [-(np.sqrt(6))/6, -(np.sqrt(6))/6, (np.sqrt(6))/3], [(1/np.sqrt(6)), -(2/np.sqrt(6)), 0]]) #Eqn 1\n",
    "print(hsi_mat)\n",
    "\n",
    "for y in range(h):\n",
    "    for x in range(w):\n",
    "        rgb = img_np[y][x]\n",
    "        rgb = rgb.reshape((3, 1))\n",
    "        out = np.matmul(hsi_mat, rgb)\n",
    "        I[y][x] = out[0][0]\n",
    "        V1[y][x] = out[1][0]\n",
    "        V2[y][x] = out[2][0]\n",
    "        S[y][x] = np.sqrt((np.square(V1[y][x])) + np.square(V2[y][x])) #Eqn 2\n",
    "        if V1[y][x] != 1:\n",
    "            if V1[y][x] == 0 and V2[y][x] == 0:\n",
    "                H[y][x] = 0\n",
    "                continue\n",
    "            elif V1[y][x] == 0:\n",
    "                H[y][x] = 0\n",
    "                continue\n",
    "            H[y][x] = np.arctan((V2[y][x])/V1[y][x]) #Eqn 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "id": "jU7orbaaQOMR"
   },
   "outputs": [],
   "source": [
    "H_norm = (H - np.min(H)) / (np.max(H) - np.min(H))\n",
    "I_norm = (I - np.min(I)) / (np.max(I) - np.min(I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nwNpY0VVfFKL",
    "outputId": "829ce1cc-6a5d-49ec-ba17-00d261b2612f"
   },
   "outputs": [],
   "source": [
    "#Computing r-map\n",
    "r_map = (H_norm + 1) / (I_norm + 1) #Eqn 4\n",
    "\n",
    "r_map_scaled = 255 * ((r_map - np.min(r_map)) / (np.max(r_map) - np.min(r_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "aH7XDhUcf4Fu",
    "outputId": "0535015a-b873-47c7-f085-7185ba4a2174"
   },
   "outputs": [],
   "source": [
    "#Shadow map and Threshold\n",
    "P = {}\n",
    "\n",
    "for y in range(r_map_scaled.shape[0]):\n",
    "    for x in range(r_map_scaled.shape[1]):\n",
    "        keys_list = P.keys()\n",
    "        if int(r_map_scaled[y][x]) in keys_list:\n",
    "            P[int(r_map_scaled[y][x])] += 1\n",
    "        else:\n",
    "            P[int(r_map_scaled[y][x])] = 1\n",
    "\n",
    "for key in P.keys():\n",
    "    P[key] = P[key] / (h * w)\n",
    "\n",
    "T_dict = {}\n",
    "\n",
    "for t in range(0, 256):\n",
    "    W1, W2 = 0, 0\n",
    "    for i in range(0, t+1):\n",
    "        if i in P.keys():\n",
    "            W1 += P[i]\n",
    "    for i in range(t+1, 256):\n",
    "        if i in P.keys():\n",
    "            W2 += P[i]\n",
    "\n",
    "    mu1, mu2 = 0, 0\n",
    "    for i in range(0, t+1):\n",
    "        if i in P.keys():\n",
    "            mu1 += (i * P[i]) / W1\n",
    "    for i in range(t+1, 256):\n",
    "        if i in P.keys():\n",
    "            mu2 += (i * P[i]) / W2\n",
    "\n",
    "    t1, t2 = 0, 0\n",
    "    for i in range(0, t+1):\n",
    "        if i in P.keys():\n",
    "            t1 += P[i] * ((i - mu1) ** 2)\n",
    "    for i in range(t+1, 256):\n",
    "        if i in P.keys():\n",
    "            t2 += P[i] * ((i - mu2) ** 2)\n",
    "\n",
    "    T_dict[t] = t1+t2\n",
    "\n",
    "\n",
    "lt = []\n",
    "for key in T_dict.keys():\n",
    "    lt.append(T_dict[key])\n",
    "\n",
    "T = lt.index(min(lt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "id": "C2FL8Sb2khdh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shadow map\n",
    "s = np.where(r_map_scaled > T, 1, 0)\n",
    "\n",
    "s_inv = np.where(r_map_scaled > T, 0, 1)\n",
    "cv2.imwrite('shadow_map.jpg', s_inv * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shadow Image\n",
    "lmd_1 = 0.7\n",
    "SI_1 = np.where(s_inv == 0, lmd_1 * img_bgr + (1 - lmd_1) * s_inv, img_bgr)\n",
    "\n",
    "cv2.imwrite('shadow_image_lmb_0.8.jpg', SI_1)\n",
    "\n",
    "lmd_2 = 1.3\n",
    "SI_2 = np.where(s_inv == 0, lmd_2 * img_bgr + (1 - lmd_2) * s_inv, img_bgr)\n",
    "\n",
    "cv2.imwrite('shadow_image_lmd_1.3.jpg', SI_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1.2 Line Draft Generation\n",
    "\n",
    "img_gray = cv2.imread('image2.jpg', 0)\n",
    "\n",
    "def bilateral_filter(image, diameter, sigma_color, sigma_space):\n",
    "    filtered_image = np.zeros_like(image)\n",
    "    height, width = image.shape\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            weighted_sum = 0\n",
    "            normalization = 0\n",
    "\n",
    "            for i in range(-diameter // 2, diameter // 2 + 1):\n",
    "                for j in range(-diameter // 2, diameter // 2 + 1):\n",
    "                    neighbor_y = y + i\n",
    "                    neighbor_x = x + j\n",
    "\n",
    "                    if 0 <= neighbor_y < height and 0 <= neighbor_x < width:\n",
    "                        color_difference = image[neighbor_y, neighbor_x] - image[y, x]\n",
    "                        color_weight = np.exp(-np.square(color_difference) / (2 * sigma_color * sigma_color))\n",
    "                        spatial_weight = np.exp(-np.square(i) + np.square(j) / (2 * sigma_space * sigma_space))\n",
    "\n",
    "                        weight = color_weight * spatial_weight\n",
    "\n",
    "                        weighted_sum += weight * image[neighbor_y, neighbor_x]\n",
    "                        normalization += weight\n",
    "\n",
    "            filtered_image[y, x] = weighted_sum / normalization\n",
    "\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/fhnqsgs157jf_ft4qz5_j92c0000gn/T/ipykernel_71052/188239627.py:20: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  color_difference = image[neighbor_y, neighbor_x] - image[y, x]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m sigma_color \u001b[39min\u001b[39;00m sigma_colors:\n\u001b[1;32m      7\u001b[0m     \u001b[39mfor\u001b[39;00m sigma_space \u001b[39min\u001b[39;00m sigma_spaces:\n\u001b[0;32m----> 8\u001b[0m         filtered_image \u001b[39m=\u001b[39m bilateral_filter(img_gray, diameter, sigma_color, sigma_space)\n\u001b[1;32m      9\u001b[0m         cv2\u001b[39m.\u001b[39mimwrite(\u001b[39m'\u001b[39m\u001b[39mbilateral_output\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(sigma_color) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(sigma_space) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m, filtered_image)\n",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m, in \u001b[0;36mbilateral_filter\u001b[0;34m(image, diameter, sigma_color, sigma_space)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m neighbor_y \u001b[39m<\u001b[39m height \u001b[39mand\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m neighbor_x \u001b[39m<\u001b[39m width:\n\u001b[1;32m     20\u001b[0m     color_difference \u001b[39m=\u001b[39m image[neighbor_y, neighbor_x] \u001b[39m-\u001b[39m image[y, x]\n\u001b[0;32m---> 21\u001b[0m     color_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39;49mnp\u001b[39m.\u001b[39;49msquare(color_difference) \u001b[39m/\u001b[39;49m (\u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m sigma_color \u001b[39m*\u001b[39;49m sigma_color))\n\u001b[1;32m     22\u001b[0m     spatial_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39msquare(i) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39msquare(j) \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m sigma_space \u001b[39m*\u001b[39m sigma_space))\n\u001b[1;32m     24\u001b[0m     weight \u001b[39m=\u001b[39m color_weight \u001b[39m*\u001b[39m spatial_weight\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "diameter = 3\n",
    "sigma_colors = [10, 30, 50, 70, 100]\n",
    "sigma_spaces = [10, 30, 50, 70, 100]\n",
    "\n",
    "#Bilateral Filtering\n",
    "for sigma_color in sigma_colors:\n",
    "    for sigma_space in sigma_spaces:\n",
    "        filtered_image = bilateral_filter(img_gray, diameter, sigma_color, sigma_space)\n",
    "        cv2.imwrite('bilateral_output' + '_' + str(sigma_color) + '_' +str(sigma_space) + '.jpg', filtered_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/fhnqsgs157jf_ft4qz5_j92c0000gn/T/ipykernel_6936/188239627.py:20: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  color_difference = image[neighbor_y, neighbor_x] - image[y, x]\n"
     ]
    }
   ],
   "source": [
    "#Test block\n",
    "\n",
    "diameter = 5\n",
    "sigma_colors = [50,]\n",
    "sigma_spaces = [50,]\n",
    "\n",
    "#Bilateral Filtering\n",
    "for sigma_color in sigma_colors:\n",
    "    for sigma_space in sigma_spaces:\n",
    "        filtered_image = bilateral_filter(img_gray, diameter, sigma_color, sigma_space)\n",
    "        cv2.imwrite('dia_5/bilateral_output' + '_' + str(sigma_color) + '_' +str(sigma_space) + '.jpg', filtered_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Edge Detection\n",
    "\n",
    "#Best sigma_color = , Best sigma_space = \n",
    "bil_img = cv2.imread('dia_5/bilateral_output_50_50.jpg', 0)\n",
    "\n",
    "sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "sobel_y = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
    "\n",
    "padded_image = np.pad(bil_img, ((1, 1), (1, 1)), mode='edge')\n",
    "\n",
    "gradient_x = np.zeros_like(bil_img, dtype=np.float32)\n",
    "gradient_y = np.zeros_like(bil_img, dtype=np.float32)\n",
    "\n",
    "for y in range(bil_img.shape[0]):\n",
    "    for x in range(bil_img.shape[1]):\n",
    "        gradient_x[y, x] = np.sum(padded_image[y:y+3, x:x+3] * sobel_x)\n",
    "        gradient_y[y, x] = np.sum(padded_image[y:y+3, x:x+3] * sobel_y)\n",
    "\n",
    "edge_map = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "\n",
    "cv2.imwrite('edge_map_dia5_50,50.jpg', edge_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Line Draft using Threshold\n",
    "ld_thresh = 130\n",
    "\n",
    "line_draft = np.where(edge_map >= ld_thresh, 1, 0)\n",
    "\n",
    "line_draft_inv = 255 * np.where(edge_map >= ld_thresh, 0, 1)\n",
    "\n",
    "cv2.imwrite('line_draft_inv_dia5_thr120.jpg', line_draft_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 255.0\n",
      "(480, 640, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.2 Color Adjustment Step\n",
    "\n",
    "#img_bgr_processed = img_bgr.astype(\"float32\") / 255\n",
    "\n",
    "lab_img = cv2.cvtColor(img_bgr.copy(), cv2.COLOR_BGR2LAB)\n",
    "\n",
    "l, a, b = np.float64(lab_img[:,:,0]), np.float64(lab_img[:,:,1]), np.float64(lab_img[:,:,2])\n",
    "# l_mid = np.int8(50)\n",
    "# l_mid = float(127)\n",
    "l_mid = 60\n",
    "print(np.min(l), np.max(l)) \n",
    "# l = ((l - np.min(l)) / (np.max(l) - np.min(l))) * 100.0\n",
    "\n",
    "\n",
    "neutral_l = np.ones((h, w)) * l_mid\n",
    "# neutral_l = np.array(neutral_l, dtype=np.uint8)\n",
    "\n",
    "chromatic_map = np.dstack((neutral_l, a, b))\n",
    "print(chromatic_map.shape)\n",
    "chromatic_map = np.array(chromatic_map, dtype = np.uint8)\n",
    "\n",
    "chromatic_map_rgb = cv2.cvtColor(chromatic_map.copy(), cv2.COLOR_LAB2RGB)\n",
    "\n",
    "cv2.imwrite('lab_img.jpg', lab_img)\n",
    "cv2.imwrite('chromatic_map.jpg', cv2.cvtColor(chromatic_map_rgb, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SI is BGR\n",
    "\n",
    "SI = SI_1.copy()\n",
    "rho = 0.005 #[0.005, 0.2]\n",
    "\n",
    "SI = np.array(SI, dtype=np.uint8)\n",
    "\n",
    "SI = cv2.cvtColor(SI, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "SI = np.array(SI, dtype=np.float64)\n",
    "\n",
    "SI_prime = SI * ((1 + np.tanh(rho * (chromatic_map_rgb - 128))) / 2)\n",
    "SI_prime = np.array(SI_prime, dtype=np.uint8)\n",
    "\n",
    "cv2.imwrite('shadow_image_color_enhanced.jpg', cv2.cvtColor(SI_prime, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saturation Correction\n",
    "\n",
    "saturation_scale = 1.3\n",
    "\n",
    "# SI_corrected = SI_prime * saturation_scale\n",
    "# SI_corrected = np.clip(SI_corrected, 0, 255)\n",
    "# SI_corrected = np.array(SI_corrected, dtype=np.uint8)\n",
    "\n",
    "SI_prime_HSV = cv2.cvtColor(SI_prime, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "H = SI_prime_HSV[:, :, 0].copy()\n",
    "S = SI_prime_HSV[:, :, 1].copy()\n",
    "V = SI_prime_HSV[:, :, 2].copy()\n",
    "\n",
    "S_corrected = np.array(np.round(255 * ((S - np.min(S)) / (np.max(S) - np.min(S))))).astype(int)\n",
    "\n",
    "S_corrected = S_corrected * saturation_scale\n",
    "S_corrected = np.clip(S_corrected, 0, 255)\n",
    "\n",
    "S_corrected = np.array(S_corrected, dtype=np.uint8)\n",
    "\n",
    "SI_corrected = np.stack((H, S_corrected, V), axis = -1) #Why not S\n",
    "\n",
    "SI_corrected_RGB = cv2.cvtColor(SI_corrected, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "cv2.imwrite('shadow_image_corrected.jpg', cv2.cvtColor(SI_corrected, cv2.COLOR_HSV2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Test of histogram equilization on s channel of HSV image\n",
    "# SI_prime_HSV = cv2.cvtColor(SI_prime, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "# H = SI_prime_HSV[:, :, 0].copy()\n",
    "# S = SI_prime_HSV[:, :, 1].copy()\n",
    "# V = SI_prime_HSV[:, :, 2].copy()\n",
    "\n",
    "# def hist_of_image(l):\n",
    "#     intensity_dict = {}\n",
    "#     h, w = l.shape\n",
    "#     for i in range(0, 256):\n",
    "#         intensity_dict[i] = 0\n",
    "#     for y in range(h):\n",
    "#         for x in range(w):\n",
    "#             intensity_dict[int(l[y, x])] += 1\n",
    "#     # keys = list(intensity_dict.keys())\n",
    "#     # keys.sort()\n",
    "#     # sorted_dict = {i: intensity_dict[i] for i in keys}\n",
    "#     return intensity_dict\n",
    "\n",
    "# def hist_eq(src_img, l_dict):\n",
    "#     h, w = src_img.shape\n",
    "#     pr = 0\n",
    "#     pixel_cdf = {}\n",
    "#     intensity_map = {}\n",
    "\n",
    "#     keys = list(l_dict.keys())\n",
    "#     for i in keys:\n",
    "#         # if not bool(unnorm_cdf):\n",
    "#         #     unnorm_cdf[i] = l_dict[i]\n",
    "#         # else:\n",
    "#         #     unnorm_cdf[i] = unnorm_cdf[int(keys[i-1])] + l_dict[i]\n",
    "#         pr += l_dict[i] / (h * w)\n",
    "#         pixel_cdf[i] = pr\n",
    "#         intensity = int(pr * 255.0)\n",
    "#         intensity_map[i] = intensity\n",
    "\n",
    "#     eq_image = src_img.copy()\n",
    "#     for y in range(h):\n",
    "#         for x in range(w):\n",
    "#             eq_image[y, x] = intensity_map[int(eq_image[y, x])]\n",
    "\n",
    "#     return eq_image\n",
    "\n",
    "# hist_dictionary = hist_of_image(S.copy())\n",
    "# S_corrected = hist_eq(S, hist_dictionary)\n",
    "# S_corrected = np.array(S_corrected, dtype=np.uint8)\n",
    "\n",
    "# SI_corrected = np.stack((H, S_corrected, V), axis = -1) #Why not S\n",
    "\n",
    "# SI_corrected_RGB = cv2.cvtColor(SI_corrected, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "# cv2.imwrite('shadow_image_corrected.jpg', cv2.cvtColor(SI_corrected, cv2.COLOR_HSV2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Artistic Enhanced Image\n",
    "beta = 0.75 #[0, 1]\n",
    "\n",
    "line_draft_inv_3d = np.stack([line_draft_inv, line_draft_inv, line_draft_inv], axis = -1) \n",
    "\n",
    "artistic_image = np.where(line_draft_inv_3d == 0, beta * SI_corrected_RGB, SI_corrected_RGB)\n",
    "\n",
    "artistic_image = np.array(artistic_image, dtype=np.uint8)\n",
    "\n",
    "cv2.imwrite('artistic_image.jpg', cv2.cvtColor(artistic_image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 Quantization\n",
    "\n",
    "#Median Cut\n",
    "\n",
    "median_cut_image = artistic_image.copy()\n",
    "\n",
    "def median_cut_quantize(img, flattened_arr):\n",
    "    r_avg = np.mean(flattened_arr[:,0])\n",
    "    g_avg = np.mean(flattened_arr[:,1])\n",
    "    b_avg = np.mean(flattened_arr[:,2])\n",
    "    \n",
    "    for data in flattened_arr:\n",
    "        img[data[3], data[4]] = [r_avg, g_avg, b_avg]\n",
    "\n",
    "def split_into_bins(img, flattened_arr, depth):  \n",
    "    if depth == 0:\n",
    "        median_cut_quantize(img, flattened_arr)\n",
    "        return  \n",
    "    ranges = np.ptp(flattened_arr, axis=0)\n",
    "    r_range, g_range, b_range = ranges[0], ranges[1], ranges[2]\n",
    "\n",
    "    rgb_val = [r_range, g_range, b_range]\n",
    "    range_idx = rgb_val.index(max(rgb_val))\n",
    "\n",
    "    flattened_arr = flattened_arr[flattened_arr[:,range_idx].argsort()]\n",
    "    median_index = int((len(flattened_arr)+1)/2)\n",
    "\n",
    "    split_into_bins(img, flattened_arr[0:median_index], depth-1)\n",
    "    split_into_bins(img, flattened_arr[median_index:], depth-1)\n",
    "\n",
    "\n",
    "flattened_img_array = []\n",
    "for rindex, rows in enumerate(median_cut_image):\n",
    "    for cindex, color in enumerate(rows):\n",
    "        flattened_img_array.append([color[0],color[1],color[2],rindex, cindex]) \n",
    "        \n",
    "flattened_img_array = np.array(flattened_img_array)\n",
    "        \n",
    "split_into_bins(median_cut_image, flattened_img_array, 5) #2^2 = 4 colors\n",
    "\n",
    "cv2.imwrite('median_cut_quantized_image.jpg', cv2.cvtColor(median_cut_image, cv2.COLOR_RGB2BGR))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Floyed Steinbeirg Dithering\n",
    "\n",
    "# color_palette = 4 #4 colours per channel of RGB\n",
    "\n",
    "# rgb_values = np.linspace(0, 255, num=color_palette)\n",
    "# r_values, g_values, b_values = rgb_values, rgb_values, rgb_values\n",
    "\n",
    "# r_values = list(set(median_cut_image[:, :, 0].flatten()))\n",
    "# g_values = list(set(median_cut_image[:, :, 1].flatten()))\n",
    "# b_values = list(set(median_cut_image[:, :, 2].flatten()))\n",
    "\n",
    "# print(r_values, g_values, b_values)\n",
    "\n",
    "# indices = np.indices((len(r_values), len(g_values), len(b_values)))\n",
    "\n",
    "# combinations = np.array(np.meshgrid(r_values, g_values, b_values)).T.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for y in range(h):\n",
    "#     for x in range(w):\n",
    "#         pix = median_cut_image[y, x]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_image = median_cut_image.copy()\n",
    "\n",
    "original_image = artistic_image.copy()\n",
    "# original_image = cv2.imread('image2.jpg', )\n",
    "\n",
    "flattened_array = median_cut_image.reshape(-1, 3)\n",
    "unique_pixel_values = np.array(np.unique(flattened_array, axis=0), dtype=np.float64)\n",
    "\n",
    "def calc_distance(p1, p2):\n",
    "    return np.sum(np.abs(p1 - p2))\n",
    "\n",
    "def nearestpixel(pix):\n",
    "    min_distance = float('inf')\n",
    "    closest_pixel = None\n",
    "    \n",
    "    for unique_pixel in unique_pixel_values:\n",
    "        distance = calc_distance(pix, unique_pixel)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_pixel = unique_pixel\n",
    "    return closest_pixel\n",
    "\n",
    "def apply_floyd_steinberg_dithering(org_image, quant_image):\n",
    "    new_image = np.array(org_image.copy(), dtype=np.float64)\n",
    "    height, width, _ = new_image.shape\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            pix = new_image[y, x].copy()\n",
    "            new_pixel = nearestpixel(pix.copy())\n",
    "            new_image[y, x] = new_pixel\n",
    "            \n",
    "            quantization_error = pix - new_pixel\n",
    "\n",
    "            if x + 1 < width:\n",
    "                new_image[y, x + 1] = new_image[y, x + 1] + quantization_error * 7 / 16\n",
    "            if y + 1 < height:\n",
    "                if x - 1 >= 0:\n",
    "                    new_image[y + 1, x - 1] = new_image[y + 1, x - 1] + quantization_error * 3 / 16\n",
    "                quant_image[y + 1, x] = quant_image[y + 1, x] + quantization_error * 5 / 16\n",
    "                if x + 1 < width:\n",
    "                    new_image[y + 1, x + 1] = new_image[y + 1, x + 1] + quantization_error * 1 / 16\n",
    "    \n",
    "    dithered_image = np.array(new_image, dtype=np.uint8)\n",
    "    return dithered_image\n",
    "\n",
    "cv2.imwrite('sample1.jpg', cv2.cvtColor(original_image, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite('sample2.jpg', cv2.cvtColor(quantized_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "dithered_image = apply_floyd_steinberg_dithering(original_image, quantized_image)\n",
    "\n",
    "# Save the dithered image\n",
    "dithered_image_path = 'dithered_image_quant.jpg'\n",
    "cv2.imwrite('dithered_image.jpg', cv2.cvtColor(dithered_image, cv2.COLOR_RGB2BGR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Color Transfer\n",
    "\n",
    "# Histogram Matching\n",
    "\n",
    "# def hist_of_image(l):\n",
    "#     intensity_dict = {}\n",
    "#     h, w = l.shape\n",
    "#     for y in range(h):\n",
    "#         for x in range(w):\n",
    "#             if int(l[y, x]) not in intensity_dict.keys():\n",
    "#                 intensity_dict[int(l[y, x])] = 1\n",
    "#             else:\n",
    "#                 intensity_dict[int(l[y, x])] += 1\n",
    "#     keys = list(intensity_dict.keys())\n",
    "#     keys.sort()\n",
    "#     sorted_dict = {i: intensity_dict[i] for i in keys}\n",
    "#     return sorted_dict\n",
    "\n",
    "# def hist_eq(src_img, l_dict):\n",
    "#     h, w = src_img.shape\n",
    "#     pr = 0\n",
    "#     pixel_cdf = {}\n",
    "#     intensity_map = {}\n",
    "\n",
    "#     keys = list(l_dict.keys())\n",
    "#     for i in keys:\n",
    "#         # if not bool(unnorm_cdf):\n",
    "#         #     unnorm_cdf[i] = l_dict[i]\n",
    "#         # else:\n",
    "#         #     unnorm_cdf[i] = unnorm_cdf[int(keys[i-1])] + l_dict[i]\n",
    "#         pr += l_dict[i] / (h * w)\n",
    "#         pixel_cdf[i] = pr\n",
    "#         intensity = int(pr * 255.0)\n",
    "#         intensity_map[i] = intensity\n",
    "\n",
    "#     eq_image = src_img.copy()\n",
    "#     for y in range(h):\n",
    "#         for x in range(w):\n",
    "#             eq_image[y, x] = intensity_map[int(eq_image[y, x])]\n",
    "\n",
    "#     return eq_image, pixel_cdf\n",
    "\n",
    "# source_image = artistic_image.copy()\n",
    "# source_image = cv2.cvtColor(source_image, cv2.COLOR_RGB2LAB)\n",
    "\n",
    "# source_image_l = source_image[:, :, 0]\n",
    "# a, b = source_image[:, :, 1], source_image[:, :, 2]\n",
    "\n",
    "# l_dict = hist_of_image(source_image_l)\n",
    "\n",
    "# source_image_l_eq, cdf_source  = hist_eq(source_image_l, l_dict)\n",
    "# print(cdf_source)\n",
    "\n",
    "# # print(source_image_l_eq.shape, a.shape, b.shape)\n",
    "# source_image_eq = np.stack((source_image_l_eq, a, b), axis = -1)\n",
    "# source_image_eq = np.array(source_image_eq, dtype=np.uint8)\n",
    "# cv2.imwrite('source_img_eq.jpg', cv2.cvtColor(source_image_eq, cv2.COLOR_LAB2BGR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image_gray = cv2.imread('target_image_2.jpg',0)\n",
    "# target_image_gray = cv2.cvtColor(target_image, cv2.COLOR_BGR2GRAY)\n",
    "# cv2.imwrite('target_img_gray.jpg', target_image_gray)\n",
    "\n",
    "# target_gray_dict = hist_of_image(target_image_gray.copy())\n",
    "\n",
    "# target_image_eq, cdf_target  = hist_eq(target_image_gray.copy(), target_gray_dict)\n",
    "# cv2.imwrite('target_img_eq.jpg', target_image_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image_gray_to_rgb = target_image_gray.copy()\n",
    "target_image_gray_l = target_image_gray.copy()\n",
    "# target_image_gray_to_rgb = cv2.cvtColor(target_image_gray_to_rgb, cv2.COLOR_GRAY2RGB)\n",
    "# target_image_gray_to_lab = cv2.cvtColor(target_image_gray_to_rgb, cv2.COLOR_RGB2LAB)\n",
    "# target_image_gray_l = target_image_gray_to_lab[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #source_image (LAB space), cdf_source, cdf_target, target_image_gray (GRAY scale space)\n",
    "\n",
    "# cdf_target_inv = dict(map(reversed, cdf_target.items()))\n",
    "# # print(cdf_target_inv)\n",
    "\n",
    "\n",
    "\n",
    "# source_image_l = source_image[:, :, 0] #L channel of source image\n",
    "# a, b = source_image[:, :, 1], source_image[:, :, 2]\n",
    "# print(source_image_l.shape)\n",
    "# for i in range(source_image_l.shape[0]):\n",
    "#     for j in range(source_image_l.shape[1]):\n",
    "#         min_dist = float('inf')\n",
    "#         min_idx = -1\n",
    "#         pixel_src = source_image_l[i,j]\n",
    "#         prob_pixel_src = cdf_source[pixel_src]\n",
    "#         for prob_pixel_target in cdf_target_inv.keys():\n",
    "#             dist = np.abs(prob_pixel_target - prob_pixel_src)\n",
    "#             if dist < min_dist:\n",
    "#                 min_dist = dist\n",
    "#                 min_idx = prob_pixel_target\n",
    "#         source_image_l[i, j] = cdf_target_inv[min_idx]\n",
    "\n",
    "# source_image_matched = np.stack((source_image_l, a, b), axis = -1)\n",
    "# source_image_matched = np.array(source_image_matched, dtype=np.uint8)\n",
    "# cv2.imwrite('source_img_matched.jpg', cv2.cvtColor(source_image_matched, cv2.COLOR_LAB2BGR))         \n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# def histogram_match_lab(rgb_img, gray_img):\n",
    "#     # Convert RGB image to LAB color space\n",
    "#     lab_img = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2LAB)\n",
    "\n",
    "#     # Calculate histograms for the luminance channel of both images\n",
    "#     hist_rgb, _ = np.histogram(lab_img[:,:,0], bins=256, range=(0, 256))\n",
    "#     hist_gray, _ = np.histogram(gray_img, bins=256, range=(0, 256))\n",
    "\n",
    "#     # Calculate cumulative distribution functions (CDFs)\n",
    "#     cdf_rgb = hist_rgb.cumsum() / hist_rgb.sum()\n",
    "#     cdf_gray = hist_gray.cumsum() / hist_gray.sum()\n",
    "\n",
    "#     # Create a mapping from the RGB luminance values to grayscale CDF values\n",
    "#     mapping = np.interp(cdf_rgb, cdf_gray, np.arange(256))\n",
    "\n",
    "#     # Apply the mapping to the luminance channel of the LAB image\n",
    "#     lab_img[:,:,0] = np.interp(lab_img[:,:,0], np.arange(256), mapping)\n",
    "\n",
    "#     # Convert the matched LAB image back to RGB\n",
    "#     matched_rgb_img = cv2.cvtColor(lab_img, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "#     return matched_rgb_img\n",
    "\n",
    "# # Read the RGB and grayscale images\n",
    "# rgb_image = cv2.imread('artistic_image.jpg')\n",
    "# rgb_image = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2RGB)\n",
    "# gray_image = cv2.imread('target_img_gray.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# # Perform histogram matching\n",
    "# matched_rgb_image = histogram_match_lab(rgb_image, gray_image)\n",
    "\n",
    "# # Display or save the matched RGB image\n",
    "# cv2.imwrite('sample.jpg', cv2.cvtColor(matched_rgb_image, cv2.COLOR_RGB2BGR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_matching(source_image, target_image):\n",
    "    # Calculate histograms of the source and target images\n",
    "    source_hist, _ = np.histogram(source_image.flatten(), bins=256, range=(0, 256), density=True)\n",
    "    target_hist, _ = np.histogram(target_image.flatten(), bins=256, range=(0, 256), density=True)\n",
    "\n",
    "    # Calculate cumulative distribution functions (CDF)\n",
    "    source_cdf = source_hist.cumsum()\n",
    "    target_cdf = target_hist.cumsum()\n",
    "\n",
    "    # Create a mapping from source CDF to target CDF\n",
    "    mapping = np.interp(source_cdf, target_cdf, np.arange(256))\n",
    "\n",
    "    # Apply mapping to the source image\n",
    "    matched_image = mapping[source_image]\n",
    "\n",
    "    return matched_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 Color Transfer\n",
    "\n",
    "#Global transfer\n",
    "\n",
    "# source_image = img.copy()\n",
    "# cv2.imwrite('samplecheck1.jpg', cv2.cvtColor(source_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "def match_images(source_image, target_image):\n",
    "    source_image_lab = cv2.cvtColor(source_image, cv2.COLOR_RGB2LAB)\n",
    "    source_image_l_norm = source_image_lab[:, :, 0]\n",
    "    a, b = source_image_lab[:, :, 1], source_image_lab[:, :, 2]\n",
    "    source_image_l_norm = np.array(source_image_l_norm, dtype=np.float64) / 255.0\n",
    "    # print(\"CHECK MAX AND MIN OF SOURCE: \", np.max(source_image_l_norm), np.min(source_image_l_norm))\n",
    "\n",
    "\n",
    "    # target_image_wo_norm = target_image_gray.copy()\n",
    "    target_image_wo_norm = target_image.copy()\n",
    "\n",
    "    # print(target_image_wo_norm)\n",
    "    # cv2.imwrite('samplecheck1.jpg', target_image_norm)\n",
    "    target_image_norm = np.array(target_image_wo_norm, dtype=np.float64) / 255.0\n",
    "    # print(\"CHECK MAX AND MIN OF TARGET: \", np.max(target_image_norm), np.min(target_image_norm))\n",
    "\n",
    "    # print(target_image_norm)\n",
    "    # print(source_image_l_norm)\n",
    "\n",
    "    mu_target = np.mean(target_image_norm)\n",
    "    sigma_target = np.std(target_image_norm)\n",
    "\n",
    "    mu_source = np.mean(source_image_l_norm)\n",
    "    sigma_source = np.std(source_image_l_norm)\n",
    "\n",
    "    source_image_l_linshift_pre = ((sigma_target/sigma_source) * (source_image_l_norm - mu_source)) + mu_target\n",
    "\n",
    "    source_image_l_linshift = (source_image_l_linshift_pre - np.min(source_image_l_linshift_pre)) / (np.max(source_image_l_linshift_pre) - np.min(source_image_l_linshift_pre))\n",
    "\n",
    "    source_image_l_linshift *= 255.0\n",
    "    source_image_l_linshift = np.clip(source_image_l_linshift, 0, 255)\n",
    "\n",
    "    source_image_linshift = np.dstack((source_image_l_linshift, a, b))\n",
    "\n",
    "    return source_image_linshift\n",
    "\n",
    "source_img = cv2.imread('artistic_image.jpg')\n",
    "source_img_rgb = cv2.cvtColor(source_img, cv2.COLOR_BGR2RGB)\n",
    "target_img = cv2.imread('target_image_2.jpg', 0)\n",
    "\n",
    "source_image_linshift = match_images(source_img_rgb, target_img)\n",
    "\n",
    "# source_image_lab = cv2.cvtColor(source_img_rgb, cv2.COLOR_RGB2LAB)\n",
    "# l = source_image_lab[:, :, 0]\n",
    "# a, b = source_image_lab[:, :, 1], source_image_lab[:, :, 2]\n",
    "\n",
    "# source_image_l = histogram_matching(l, target_img)\n",
    "\n",
    "# source_image_linshift = np.dstack((source_image_l, a, b))\n",
    "\n",
    "# source_image_l_linshift = np.clip(source_image_l_linshift, 0.0, 255.0)\n",
    "\n",
    "source_image_linshift_uint = np.array(source_image_linshift, dtype=np.uint8)\n",
    "# cv2.imwrite(\"l_linshift_check.jpg\", np.array(source_image_l_linshift, dtype=np.uint8))\n",
    "\n",
    "\n",
    "cv2.imwrite('source_image_linshift.jpg', cv2.cvtColor(source_image_linshift_uint, cv2.COLOR_LAB2BGR))\n",
    "# print(source_image_l_linshift)\n",
    "\n",
    "\n",
    "#test\n",
    "\n",
    "# mu_target = np.mean(target_image_wo_norm)\n",
    "# sigma_target = np.std(target_image_wo_norm)\n",
    "\n",
    "# mu_source = np.mean(source_image_l_linshift)\n",
    "# sigma_source = np.std(source_image_l_linshift)\n",
    "\n",
    "# print(mu_target, sigma_target, mu_source, sigma_source)\n",
    "# print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Remove it at the end\n",
    "# #histogram matching\n",
    "# # source_image_linshift = source_image.copy()\n",
    "\n",
    "# import cv2\n",
    "\n",
    "# def match_histograms(source_gray, target_gray):\n",
    "#     # Convert images to grayscale\n",
    "#     # source_gray = cv2.cvtColor(source_image, cv2.COLOR_BGR2GRAY)\n",
    "#     # target_gray = cv2.cvtColor(target_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Calculate histograms of the grayscale images\n",
    "#     source_hist, _ = np.histogram(source_gray.flatten(), bins=256, range=[0, 256])\n",
    "#     target_hist, _ = np.histogram(target_gray.flatten(), bins=256, range=[0, 256])\n",
    "\n",
    "#     # Calculate cumulative distribution functions (CDFs)\n",
    "#     source_cdf = source_hist.cumsum() / source_hist.sum()\n",
    "#     target_cdf = target_hist.cumsum() / target_hist.sum()\n",
    "\n",
    "#     # Create a lookup table for histogram matching\n",
    "#     lookup_table = np.interp(source_cdf, target_cdf, np.arange(256))\n",
    "\n",
    "#     # Apply histogram matching to the source grayscale image\n",
    "#     matched_gray = cv2.LUT(source_gray, lookup_table)\n",
    "\n",
    "#     # Convert matched grayscale image to color (BGR) for visualization\n",
    "#     #matched_color = cv2.cvtColor(matched_gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "#     return matched_gray\n",
    "\n",
    "# # Load your two grayscale images\n",
    "# image1 = source_image_lab[:, :, 0].copy()\n",
    "# a, b = source_image_lab[:, :, 1].copy(), source_image_lab[:, :, 2].copy()\n",
    "# image2 = target_image_gray_l.copy()\n",
    "\n",
    "# # Match the histogram of image1 to the levels of image2\n",
    "# source_image_l_linshift = match_histograms(image1, image2)\n",
    "# source_image_linshift = np.array(np.stack((source_image_l_linshift, a, b), axis=-1), dtype=np.uint8)\n",
    "\n",
    "# cv2.imwrite('source_image_linshift.jpg', cv2.cvtColor(source_image_linshift, cv2.COLOR_LAB2BGR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[162.79578063805482, 130.0, 80.0, 8, 4], [163.81276719252952, 127.0, 83.0, 7, 63], [164.75319708541147, 126.0, 85.0, 8, 91], [164.75319708541147, 123.0, 91.0, 1, 133], [171.94063544318905, 120.0, 93.0, 29, 202], [176.11955650981525, 119.0, 97.0, 0, 230], [171.28948768698282, 121.0, 94.0, 12, 280], [176.63029373556583, 117.0, 100.0, 28, 318], [177.11124019440655, 117.0, 101.0, 5, 374], [182.3834132368519, 118.0, 107.0, 31, 395], [185.28825032622876, 117.0, 111.0, 31, 431], [186.0968724658248, 117.0, 114.0, 8, 502], [187.49706983728706, 118.0, 118.0, 11, 525], [188.62104681908227, 119.0, 120.0, 23, 550], [192.1005217292622, 116.0, 124.0, 22, 593], [168.24765332807388, 121.0, 90.0, 52, 17], [169.40664482919982, 121.0, 91.0, 50, 78], [173.46136171788865, 119.0, 96.0, 54, 121], [170.66094576365066, 120.0, 93.0, 32, 142], [176.63029373556583, 117.0, 100.0, 60, 175], [173.46136171788865, 119.0, 95.0, 41, 217], [177.76468174454297, 115.0, 102.0, 46, 257], [184.20314281235747, 112.0, 111.0, 52, 303], [186.44514687355186, 111.0, 115.0, 53, 336], [185.28825032622876, 114.0, 114.0, 44, 385], [186.44514687355186, 116.0, 115.0, 37, 441], [188.62104681908227, 116.0, 119.0, 40, 487], [191.2104126029475, 117.0, 125.0, 58, 535], [192.1005217292622, 116.0, 124.0, 51, 549], [192.1005217292622, 121.0, 125.0, 54, 606], [171.28948768698282, 120.0, 93.0, 73, 34], [171.28948768698282, 119.0, 96.0, 73, 63], [177.11124019440655, 116.0, 100.0, 79, 121], [177.11124019440655, 115.0, 101.0, 65, 164], [189.07949283576335, 110.0, 118.0, 84, 204], [155.43411208260582, 99.0, 155.0, 83, 237], [156.6292043974905, 111.0, 122.0, 83, 253], [136.77844570287792, 112.0, 152.0, 89, 322], [160.40927483530777, 117.0, 127.0, 65, 362], [168.24765332807388, 118.0, 121.0, 71, 399], [150.7673562723496, 112.0, 154.0, 88, 422], [137.88418279217845, 108.0, 156.0, 94, 481], [149.7548200570744, 106.0, 143.0, 82, 510], [193.75132056334337, 127.0, 128.0, 89, 576], [194.14076313219564, 125.0, 127.0, 86, 601], [179.02755163456663, 120.0, 103.0, 127, 30], [178.40576097479683, 118.0, 103.0, 114, 48], [180.913932894483, 116.0, 107.0, 118, 84], [139.27746387257034, 114.0, 141.0, 96, 165], [108.54807534471438, 124.0, 133.0, 123, 187], [31.00345982142857, 126.0, 130.0, 117, 248], [117.01088130546474, 117.0, 137.0, 127, 266], [144.03306199387455, 109.0, 160.0, 105, 327], [144.3841451347072, 113.0, 157.0, 126, 341], [99.08675156502424, 122.0, 133.0, 116, 387], [133.9206568864022, 124.0, 134.0, 114, 443], [147.62238468784886, 99.0, 164.0, 125, 478], [130.7238562582187, 113.0, 146.0, 114, 510], [134.39110891706505, 115.0, 138.0, 100, 546], [190.35745824604277, 127.0, 128.0, 124, 591], [179.02755163456663, 123.0, 103.0, 145, 6], [189.3651964052868, 115.0, 122.0, 148, 73], [187.49706983728706, 115.0, 118.0, 135, 91], [131.04792969583423, 114.0, 143.0, 138, 142], [86.22494605279739, 124.0, 132.0, 129, 193], [66.75344449798091, 126.0, 127.0, 151, 251], [132.93199926129168, 115.0, 147.0, 159, 252], [140.86839755725052, 109.0, 158.0, 140, 302], [155.27389871371668, 100.0, 170.0, 144, 340], [66.75344449798091, 124.0, 131.0, 144, 410], [119.31063513189109, 122.0, 134.0, 133, 441], [135.4716650880606, 136.0, 141.0, 156, 474], [131.40180619266056, 116.0, 144.0, 140, 540], [144.3841451347072, 106.0, 158.0, 129, 578], [198.8884618615588, 128.0, 128.0, 131, 627], [179.60803958914087, 125.0, 104.0, 166, 1], [119.31063513189109, 128.0, 122.0, 186, 70], [130.00753432884886, 116.0, 143.0, 185, 91], [108.54807534471438, 122.0, 131.0, 181, 153], [135.4716650880606, 118.0, 146.0, 165, 195], [104.69281395818378, 126.0, 133.0, 186, 214], [163.81276719252952, 118.0, 149.0, 170, 269], [160.79753238485384, 137.0, 140.0, 185, 313], [152.0401597913805, 109.0, 161.0, 170, 362], [153.85441669264338, 101.0, 167.0, 183, 415], [159.71604883603237, 108.0, 176.0, 171, 456], [143.00721266936392, 128.0, 140.0, 170, 468], [132.05420973050337, 115.0, 146.0, 176, 543], [153.59381039588527, 99.0, 170.0, 182, 550], [133.20095559768774, 105.0, 150.0, 182, 600], [181.923419355646, 128.0, 107.0, 202, 9], [150.4225306978334, 127.0, 125.0, 220, 54], [99.08675156502424, 130.0, 130.0, 200, 114], [133.20095559768774, 131.0, 121.0, 217, 166], [161.53052091936053, 132.0, 148.0, 217, 204], [140.86839755725052, 126.0, 160.0, 199, 211], [134.8544160679952, 117.0, 138.0, 206, 277], [137.88418279217845, 125.0, 148.0, 200, 328], [149.03748150366403, 111.0, 159.0, 223, 341], [132.35049524786302, 115.0, 146.0, 205, 415], [111.71388222867941, 122.0, 135.0, 205, 432], [99.08675156502424, 126.0, 132.0, 214, 473], [129.24481557188943, 115.0, 141.0, 213, 529], [152.0401597913805, 99.0, 166.0, 216, 572], [152.96387255322801, 103.0, 166.0, 197, 597], [150.034360045488, 118.0, 134.0, 230, 19], [161.66336475784567, 131.0, 129.0, 250, 65], [132.05420973050337, 116.0, 138.0, 246, 109], [165.72588604712206, 124.0, 127.0, 237, 143], [151.38852358824454, 128.0, 125.0, 242, 168], [158.71146641195256, 133.0, 130.0, 254, 242], [130.00753432884886, 131.0, 124.0, 239, 279], [113.85586722053382, 122.0, 133.0, 224, 334], [156.1079153349905, 141.0, 157.0, 251, 358], [31.00345982142857, 126.0, 129.0, 230, 381], [144.8937696285818, 131.0, 150.0, 247, 434], [93.4641592142283, 126.0, 133.0, 239, 503], [149.03748150366403, 134.0, 139.0, 247, 543], [93.4641592142283, 124.0, 133.0, 226, 576], [104.69281395818378, 124.0, 131.0, 226, 629], [147.24715790147002, 125.0, 136.0, 263, 17], [151.747771602349, 131.0, 135.0, 284, 72], [160.79753238485384, 140.0, 163.0, 262, 90], [142.67436689473453, 130.0, 129.0, 267, 154], [150.7673562723496, 128.0, 125.0, 282, 168], [168.24765332807388, 143.0, 161.0, 267, 227], [137.88418279217845, 128.0, 133.0, 284, 259], [151.747771602349, 134.0, 137.0, 279, 294], [142.14450210899548, 130.0, 143.0, 267, 373], [124.34274846042976, 119.0, 136.0, 282, 411], [136.25593473276408, 132.0, 144.0, 263, 451], [162.79578063805482, 152.0, 172.0, 256, 493], [139.27746387257034, 132.0, 147.0, 263, 521], [108.54807534471438, 124.0, 130.0, 274, 581], [132.35049524786302, 124.0, 129.0, 272, 612], [157.71631411205794, 127.0, 113.0, 308, 22], [140.5396809610038, 127.0, 131.0, 296, 73], [133.9206568864022, 131.0, 136.0, 309, 92], [124.34274846042976, 128.0, 126.0, 299, 153], [152.3501700935783, 135.0, 140.0, 297, 177], [113.85586722053382, 124.0, 135.0, 319, 244], [122.39094026165886, 122.0, 133.0, 308, 293], [121.51020369292996, 118.0, 138.0, 319, 335], [118.13225084067717, 120.0, 136.0, 307, 348], [119.31063513189109, 118.0, 136.0, 303, 409], [121.51020369292996, 118.0, 137.0, 292, 423], [113.85586722053382, 122.0, 134.0, 305, 490], [113.85586722053382, 120.0, 135.0, 312, 509], [132.35049524786302, 110.0, 149.0, 308, 560], [93.4641592142283, 122.0, 133.0, 296, 598], [157.60798937067077, 135.0, 85.0, 348, 2], [145.89008883127187, 125.0, 126.0, 340, 63], [99.08675156502424, 126.0, 130.0, 327, 118], [161.94815416322558, 129.0, 120.0, 321, 138], [158.26191334968064, 145.0, 157.0, 320, 205], [117.01088130546474, 122.0, 134.0, 347, 221], [111.71388222867941, 122.0, 134.0, 327, 278], [117.01088130546474, 122.0, 133.0, 328, 318], [127.63732238485491, 120.0, 139.0, 342, 358], [108.54807534471438, 122.0, 134.0, 345, 390], [127.63732238485491, 125.0, 134.0, 344, 456], [113.85586722053382, 120.0, 135.0, 347, 498], [66.75344449798091, 124.0, 131.0, 340, 521], [115.6744855330031, 120.0, 136.0, 340, 564], [111.71388222867941, 120.0, 134.0, 348, 593], [152.3501700935783, 146.0, 75.0, 367, 40], [93.4641592142283, 124.0, 126.0, 359, 75], [37.896353024488306, 126.0, 130.0, 358, 110], [104.69281395818378, 122.0, 133.0, 367, 145], [111.71388222867941, 120.0, 134.0, 361, 197], [117.01088130546474, 120.0, 136.0, 353, 222], [99.08675156502424, 122.0, 133.0, 378, 289], [66.75344449798091, 124.0, 130.0, 378, 330], [121.51020369292996, 118.0, 137.0, 359, 376], [99.08675156502424, 122.0, 133.0, 377, 416], [108.54807534471438, 122.0, 132.0, 353, 429], [108.54807534471438, 122.0, 132.0, 353, 479], [86.22494605279739, 124.0, 131.0, 354, 518], [119.31063513189109, 120.0, 137.0, 353, 558], [160.26505324817316, 128.0, 102.0, 381, 615], [150.7673562723496, 145.0, 77.0, 390, 36], [145.89008883127187, 147.0, 78.0, 407, 57], [148.75351831019356, 144.0, 81.0, 403, 120], [31.00345982142857, 126.0, 130.0, 410, 143], [52.095989280523256, 126.0, 130.0, 414, 202], [99.08675156502424, 122.0, 133.0, 391, 247], [86.22494605279739, 122.0, 132.0, 386, 285], [93.4641592142283, 124.0, 130.0, 414, 309], [86.22494605279739, 124.0, 132.0, 396, 362], [93.4641592142283, 122.0, 133.0, 409, 415], [93.4641592142283, 122.0, 133.0, 394, 458], [93.4641592142283, 122.0, 133.0, 415, 479], [104.69281395818378, 122.0, 133.0, 407, 526], [104.69281395818378, 124.0, 130.0, 412, 559], [154.62840693981005, 124.0, 108.0, 387, 588], [133.9206568864022, 141.0, 93.0, 445, 29], [136.25593473276408, 143.0, 88.0, 431, 78], [140.00635780198272, 142.0, 88.0, 422, 114], [135.88028899690252, 133.0, 101.0, 434, 147], [66.75344449798091, 126.0, 129.0, 416, 196], [86.22494605279739, 122.0, 132.0, 423, 229], [66.75344449798091, 124.0, 131.0, 443, 281], [86.22494605279739, 122.0, 132.0, 434, 303], [52.095989280523256, 124.0, 130.0, 447, 376], [128.8203698410682, 120.0, 126.0, 439, 387], [132.93199926129168, 127.0, 113.0, 442, 432], [66.75344449798091, 124.0, 130.0, 433, 465], [122.39094026165886, 132.0, 126.0, 438, 527], [144.03306199387455, 128.0, 107.0, 447, 567], [154.62840693981005, 129.0, 100.0, 419, 588], [132.05420973050337, 140.0, 95.0, 458, 5], [126.2458642526745, 136.0, 102.0, 471, 74], [124.34274846042976, 135.0, 107.0, 474, 95], [128.8203698410682, 131.0, 109.0, 469, 152], [127.63732238485491, 130.0, 112.0, 474, 208], [123.34978775384049, 128.0, 116.0, 477, 246], [128.26027287291103, 126.0, 117.0, 467, 280], [66.75344449798091, 124.0, 130.0, 458, 297], [124.34274846042976, 126.0, 118.0, 471, 338], [130.00753432884886, 125.0, 120.0, 461, 403], [128.8203698410682, 128.0, 118.0, 465, 425], [131.04792969583423, 127.0, 117.0, 459, 464], [135.88028899690252, 125.0, 118.0, 468, 538], [141.25457143570287, 131.0, 106.0, 448, 559], [22.218053836633665, 130.0, 126.0, 453, 593]]\n",
      "[[135.47166509 136.         141.         156.         474.        ]\n",
      " [144.89376963 131.         150.         247.         434.        ]\n",
      " [117.01088131 122.         133.         328.         318.        ]\n",
      " [165.72588605 124.         127.         237.         143.        ]\n",
      " [164.75319709 126.          85.           8.          91.        ]\n",
      " [115.67448553 120.         136.         340.         564.        ]\n",
      " [126.24586425 136.         102.         471.          74.        ]\n",
      " [132.05420973 116.         138.         246.         109.        ]\n",
      " [134.85441607 117.         138.         206.         277.        ]\n",
      " [163.81276719 127.          83.           7.          63.        ]\n",
      " [104.69281396 124.         130.         412.         559.        ]\n",
      " [149.0374815  111.         159.         223.         341.        ]\n",
      " [142.67436689 130.         129.         267.         154.        ]\n",
      " [158.71146641 133.         130.         254.         242.        ]\n",
      " [118.13225084 120.         136.         307.         348.        ]\n",
      " [ 66.7534445  124.         130.         458.         297.        ]\n",
      " [122.39094026 122.         133.         308.         293.        ]\n",
      " [113.85586722 124.         135.         319.         244.        ]\n",
      " [ 93.46415921 124.         133.         226.         576.        ]\n",
      " [177.76468174 115.         102.          46.         257.        ]\n",
      " [152.35017009 146.          75.         367.          40.        ]\n",
      " [117.01088131 120.         136.         353.         222.        ]\n",
      " [151.7477716  134.         137.         279.         294.        ]\n",
      " [149.75482006 106.         143.          82.         510.        ]\n",
      " [187.49706984 118.         118.          11.         525.        ]\n",
      " [185.28825033 117.         111.          31.         431.        ]\n",
      " [124.34274846 119.         136.         282.         411.        ]\n",
      " [128.26027287 126.         117.         467.         280.        ]\n",
      " [149.0374815  134.         139.         247.         543.        ]\n",
      " [128.82036984 131.         109.         469.         152.        ]\n",
      " [121.51020369 118.         137.         359.         376.        ]\n",
      " [ 93.46415921 124.         126.         359.          75.        ]\n",
      " [179.60803959 125.         104.         166.           1.        ]\n",
      " [108.54807534 122.         131.         181.         153.        ]\n",
      " [133.2009556  105.         150.         182.         600.        ]\n",
      " [168.24765333 118.         121.          71.         399.        ]\n",
      " [131.0479297  114.         143.         138.         142.        ]\n",
      " [156.10791533 141.         157.         251.         358.        ]\n",
      " [104.69281396 126.         133.         186.         214.        ]\n",
      " [144.38414513 113.         157.         126.         341.        ]\n",
      " [119.31063513 122.         134.         133.         441.        ]\n",
      " [129.24481557 115.         141.         213.         529.        ]\n",
      " [ 99.08675157 122.         133.         378.         289.        ]\n",
      " [168.24765333 143.         161.         267.         227.        ]\n",
      " [182.38341324 118.         107.          31.         395.        ]\n",
      " [171.94063544 120.          93.          29.         202.        ]\n",
      " [177.11124019 117.         101.           5.         374.        ]\n",
      " [131.40180619 116.         144.         140.         540.        ]\n",
      " [135.880289   125.         118.         468.         538.        ]\n",
      " [171.28948769 121.          94.          12.         280.        ]\n",
      " [137.88418279 125.         148.         200.         328.        ]\n",
      " [ 37.89635302 126.         130.         358.         110.        ]\n",
      " [122.39094026 132.         126.         438.         527.        ]\n",
      " [ 22.21805384 130.         126.         453.         593.        ]\n",
      " [130.00753433 131.         124.         239.         279.        ]\n",
      " [ 86.22494605 124.         132.         129.         193.        ]\n",
      " [132.05420973 140.          95.         458.           5.        ]\n",
      " [119.31063513 128.         122.         186.          70.        ]\n",
      " [111.71388223 120.         134.         361.         197.        ]\n",
      " [171.28948769 119.          96.          73.          63.        ]\n",
      " [ 52.09598928 126.         130.         414.         202.        ]\n",
      " [127.63732238 125.         134.         344.         456.        ]\n",
      " [140.53968096 127.         131.         296.          73.        ]\n",
      " [121.51020369 118.         137.         292.         423.        ]\n",
      " [153.5938104   99.         170.         182.         550.        ]\n",
      " [ 86.22494605 124.         132.         396.         362.        ]\n",
      " [104.69281396 124.         131.         226.         629.        ]\n",
      " [ 99.08675157 126.         132.         214.         473.        ]\n",
      " [ 86.22494605 122.         132.         423.         229.        ]\n",
      " [ 99.08675157 122.         133.         116.         387.        ]\n",
      " [128.82036984 128.         118.         465.         425.        ]\n",
      " [189.07949284 110.         118.          84.         204.        ]\n",
      " [192.10052173 116.         124.          22.         593.        ]\n",
      " [133.92065689 141.          93.         445.          29.        ]\n",
      " [ 86.22494605 122.         132.         434.         303.        ]\n",
      " [108.54807534 122.         132.         353.         479.        ]\n",
      " [ 99.08675157 122.         133.         377.         416.        ]\n",
      " [156.6292044  111.         122.          83.         253.        ]\n",
      " [155.27389871 100.         170.         144.         340.        ]\n",
      " [164.75319709 123.          91.           1.         133.        ]\n",
      " [136.25593473 143.          88.         431.          78.        ]\n",
      " [155.43411208  99.         155.          83.         237.        ]\n",
      " [ 52.09598928 124.         130.         447.         376.        ]\n",
      " [173.46136172 119.          96.          54.         121.        ]\n",
      " [135.880289   133.         101.         434.         147.        ]\n",
      " [140.86839756 126.         160.         199.         211.        ]\n",
      " [184.20314281 112.         111.          52.         303.        ]\n",
      " [186.44514687 111.         115.          53.         336.        ]\n",
      " [150.76735627 145.          77.         390.          36.        ]\n",
      " [111.71388223 122.         134.         327.         278.        ]\n",
      " [152.04015979 109.         161.         170.         362.        ]\n",
      " [171.28948769 120.          93.          73.          34.        ]\n",
      " [ 86.22494605 122.         132.         386.         285.        ]\n",
      " [150.76735627 112.         154.          88.         422.        ]\n",
      " [160.79753238 140.         163.         262.          90.        ]\n",
      " [187.49706984 115.         118.         135.          91.        ]\n",
      " [ 66.7534445  126.         129.         416.         196.        ]\n",
      " [ 66.7534445  124.         131.         144.         410.        ]\n",
      " [132.35049525 124.         129.         272.         612.        ]\n",
      " [189.36519641 115.         122.         148.          73.        ]\n",
      " [162.79578064 152.         172.         256.         493.        ]\n",
      " [161.94815416 129.         120.         321.         138.        ]\n",
      " [136.7784457  112.         152.          89.         322.        ]\n",
      " [124.34274846 135.         107.         474.          95.        ]\n",
      " [134.39110892 115.         138.         100.         546.        ]\n",
      " [158.26191335 145.         157.         320.         205.        ]\n",
      " [139.27746387 114.         141.          96.         165.        ]\n",
      " [154.62840694 129.         100.         419.         588.        ]\n",
      " [127.63732238 130.         112.         474.         208.        ]\n",
      " [104.69281396 122.         133.         367.         145.        ]\n",
      " [ 93.46415921 126.         133.         239.         503.        ]\n",
      " [124.34274846 126.         118.         471.         338.        ]\n",
      " [152.35017009 135.         140.         297.         177.        ]\n",
      " [148.75351831 144.          81.         403.         120.        ]\n",
      " [ 66.7534445  124.         130.         433.         465.        ]\n",
      " [132.35049525 115.         146.         205.         415.        ]\n",
      " [ 66.7534445  124.         131.         443.         281.        ]\n",
      " [ 93.46415921 122.         133.         409.         415.        ]\n",
      " [147.2471579  125.         136.         263.          17.        ]\n",
      " [111.71388223 120.         134.         348.         593.        ]\n",
      " [ 93.46415921 122.         133.         296.         598.        ]\n",
      " [188.62104682 119.         120.          23.         550.        ]\n",
      " [177.11124019 115.         101.          65.         164.        ]\n",
      " [140.0063578  142.          88.         422.         114.        ]\n",
      " [153.85441669 101.         167.         183.         415.        ]\n",
      " [179.02755163 120.         103.         127.          30.        ]\n",
      " [ 99.08675157 130.         130.         200.         114.        ]\n",
      " [169.40664483 121.          91.          50.          78.        ]\n",
      " [ 93.46415921 124.         130.         414.         309.        ]\n",
      " [ 66.7534445  126.         127.         151.         251.        ]\n",
      " [170.66094576 120.          93.          32.         142.        ]\n",
      " [157.60798937 135.          85.         348.           2.        ]\n",
      " [132.93199926 127.         113.         442.         432.        ]\n",
      " [133.92065689 124.         134.         114.         443.        ]\n",
      " [176.11955651 119.          97.           0.         230.        ]\n",
      " [157.71631411 127.         113.         308.          22.        ]\n",
      " [194.14076313 125.         127.          86.         601.        ]\n",
      " [113.85586722 122.         133.         224.         334.        ]\n",
      " [173.46136172 119.          95.          41.         217.        ]\n",
      " [139.27746387 132.         147.         263.         521.        ]\n",
      " [142.14450211 130.         143.         267.         373.        ]\n",
      " [144.38414513 106.         158.         129.         578.        ]\n",
      " [ 93.46415921 122.         133.         394.         458.        ]\n",
      " [176.63029374 117.         100.          60.         175.        ]\n",
      " [160.26505325 128.         102.         381.         615.        ]\n",
      " [135.47166509 118.         146.         165.         195.        ]\n",
      " [145.89008883 147.          78.         407.          57.        ]\n",
      " [178.40576097 118.         103.         114.          48.        ]\n",
      " [117.01088131 117.         137.         127.         266.        ]\n",
      " [123.34978775 128.         116.         477.         246.        ]\n",
      " [176.63029374 117.         100.          28.         318.        ]\n",
      " [113.85586722 122.         134.         305.         490.        ]\n",
      " [104.69281396 122.         133.         407.         526.        ]\n",
      " [190.35745825 127.         128.         124.         591.        ]\n",
      " [186.44514687 116.         115.          37.         441.        ]\n",
      " [198.88846186 128.         128.         131.         627.        ]\n",
      " [111.71388223 122.         135.         205.         432.        ]\n",
      " [ 86.22494605 124.         131.         354.         518.        ]\n",
      " [159.71604884 108.         176.         171.         456.        ]\n",
      " [132.93199926 115.         147.         159.         252.        ]\n",
      " [180.91393289 116.         107.         118.          84.        ]\n",
      " [108.54807534 124.         133.         123.         187.        ]\n",
      " [160.79753238 137.         140.         185.         313.        ]\n",
      " [150.76735627 128.         125.         282.         168.        ]\n",
      " [152.04015979  99.         166.         216.         572.        ]\n",
      " [ 31.00345982 126.         130.         410.         143.        ]\n",
      " [128.82036984 120.         126.         439.         387.        ]\n",
      " [121.51020369 118.         138.         319.         335.        ]\n",
      " [168.24765333 121.          90.          52.          17.        ]\n",
      " [137.88418279 128.         133.         284.         259.        ]\n",
      " [131.0479297  127.         117.         459.         464.        ]\n",
      " [177.11124019 116.         100.          79.         121.        ]\n",
      " [ 99.08675157 122.         133.         391.         247.        ]\n",
      " [152.96387255 103.         166.         197.         597.        ]\n",
      " [154.62840694 124.         108.         387.         588.        ]\n",
      " [ 66.7534445  124.         130.         378.         330.        ]\n",
      " [186.09687247 117.         114.           8.         502.        ]\n",
      " [185.28825033 114.         114.          44.         385.        ]\n",
      " [133.2009556  131.         121.         217.         166.        ]\n",
      " [141.25457144 131.         106.         448.         559.        ]\n",
      " [161.53052092 132.         148.         217.         204.        ]\n",
      " [163.81276719 118.         149.         170.         269.        ]\n",
      " [144.03306199 128.         107.         447.         567.        ]\n",
      " [ 31.00345982 126.         129.         230.         381.        ]\n",
      " [162.79578064 130.          80.           8.           4.        ]\n",
      " [ 31.00345982 126.         130.         117.         248.        ]\n",
      " [ 93.46415921 122.         133.         415.         479.        ]\n",
      " [144.03306199 109.         160.         105.         327.        ]\n",
      " [137.88418279 108.         156.          94.         481.        ]\n",
      " [143.00721267 128.         140.         170.         468.        ]\n",
      " [150.4225307  127.         125.         220.          54.        ]\n",
      " [130.00753433 116.         143.         185.          91.        ]\n",
      " [192.10052173 121.         125.          54.         606.        ]\n",
      " [188.62104682 116.         119.          40.         487.        ]\n",
      " [133.92065689 131.         136.         309.          92.        ]\n",
      " [140.86839756 109.         158.         140.         302.        ]\n",
      " [113.85586722 120.         135.         347.         498.        ]\n",
      " [ 66.7534445  124.         131.         340.         521.        ]\n",
      " [ 99.08675157 126.         130.         327.         118.        ]\n",
      " [151.38852359 128.         125.         242.         168.        ]]\n"
     ]
    }
   ],
   "source": [
    "##jitter sampling\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "import random\n",
    "\n",
    "locations = []\n",
    "\n",
    "def jitter_sampling(image_lab, num_colors):\n",
    "    h, w, _ = image_lab.shape\n",
    "    image_lab = np.array(image_lab, dtype=np.float64)\n",
    "    # print(image_lab.shape)\n",
    "    l, a, b = image_lab[:, :, 0].copy(), image_lab[:, :, 1].copy(), image_lab[:, :, 2].copy()\n",
    "\n",
    "    grid_size = int(np.ceil(np.sqrt(num_colors)))\n",
    "    grid_height = h // grid_size\n",
    "    grid_width = w // grid_size\n",
    "    # print(grid_height, grid_width)\n",
    "\n",
    "    sampled_colors = []\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            top = i * grid_height\n",
    "            bottom = (i + 1) * grid_height\n",
    "            left = j * grid_width\n",
    "            right = (j + 1) * grid_width\n",
    "\n",
    "            rand_y = random.randint(top, bottom - 1)\n",
    "            rand_x = random.randint(left, right - 1)\n",
    "\n",
    "            locations.append([l[rand_y, rand_x], a[rand_y, rand_x], b[rand_y, rand_x], rand_y, rand_x])\n",
    "            \n",
    "            # print(rand_y, rand_x, image_lab[rand_y, rand_x])\n",
    "\n",
    "            val = np.array([l[rand_y, rand_x], a[rand_y, rand_x], b[rand_y, rand_x], rand_y, rand_x], dtype=np.float64)\n",
    "            sampled_colors.append(val)\n",
    "\n",
    "    print(locations)\n",
    "    \n",
    "    if len(sampled_colors) > num_colors:\n",
    "        sampled_colors = random.sample(sampled_colors, num_colors)\n",
    "\n",
    "    return sampled_colors\n",
    "\n",
    "image_path = source_image_linshift.copy()\n",
    "num_colors = 200 #As mentioned in paper\n",
    "\n",
    "# cv2.imwrite('test2.jpg', cv2.cvtColor(image_path, cv2.COLOR_LAB2BGR))\n",
    "\n",
    "sampled_colors = jitter_sampling(image_path, num_colors)\n",
    "sampled_colors = np.array(sampled_colors, dtype=np.float64)\n",
    "# print(len(sampled_colors))\n",
    "print(sampled_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 36.90789474 121.         143.        ]\n"
     ]
    }
   ],
   "source": [
    "print(image_path[186, 488])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(471, 600)\n",
      "[[1.05527248 0.90862534 0.8908423  ... 1.09544512 1.28747816 1.25602548]\n",
      " [1.20929732 1.0851728  1.05375519 ... 1.52105227 1.57784663 1.35410487]\n",
      " [1.21720992 1.09105454 1.02449988 ... 1.49666295 1.52315462 1.29614814]\n",
      " ...\n",
      " [3.73823488 3.58083789 3.37615166 ... 8.51765226 8.52065725 8.37768464]\n",
      " [3.08700502 3.03684046 3.03315018 ... 7.74741247 7.65913833 7.46190324]\n",
      " [2.09914268 2.36169431 2.54684118 ... 4.38068488 4.5491098  4.687686  ]]\n",
      "0.44542114902640173 59.33007331868046\n"
     ]
    }
   ],
   "source": [
    "def calc_distance_val(p1, p2):\n",
    "    #print(abs(p1 - p2))\n",
    "    return abs(float(p1) - float(p2))\n",
    "\n",
    "def compute_sd(image, neighborhood_size=5):\n",
    "    amt_to_pad = (neighborhood_size - 1) // 2\n",
    "    y, x = image.shape\n",
    "    sds = np.zeros((y, x))\n",
    "\n",
    "    padded = np.pad(image, ((amt_to_pad, amt_to_pad), (amt_to_pad, amt_to_pad)), mode='edge')\n",
    "    padded = np.array(padded, dtype=np.float64)\n",
    "\n",
    "    for i in range(amt_to_pad, y + amt_to_pad):\n",
    "        for j in range(amt_to_pad, x + amt_to_pad):\n",
    "            region = padded[i - amt_to_pad:i + amt_to_pad + 1, j - amt_to_pad:j + amt_to_pad + 1]\n",
    "            # sd = np.sqrt(np.mean(np.square(region - np.mean(region))))\n",
    "            #sd = np.sqrt(region.var())\n",
    "            sd = np.std(region)\n",
    "            sds[i - amt_to_pad, j - amt_to_pad] = sd\n",
    "    return sds\n",
    "\n",
    "target_img = cv2.imread('target_image_2.jpg', 0)\n",
    "sds = compute_sd(target_img, 5)\n",
    "print(sds.shape)\n",
    "print(sds)\n",
    "print(np.min(sds), np.max(sds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test\n",
    "# lt = []\n",
    "# h, w, _ = image_path.shape\n",
    "# for i in range(h):\n",
    "#     for j in range(w):\n",
    "#         lt.append(image_path[i, j, 1])\n",
    "# lt = np.array(lt)\n",
    "# print(np.max(lt), np.min(lt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coloring(image, sds):\n",
    "    # image = target_image.copy()\n",
    "\n",
    "    # image = np.array(image, dtype=np.uint8)\n",
    "    # colored_image_lab = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # cv2.imwrite('gradient/sample1.jpg', colored_image_lab)\n",
    "    # cv2.imwrite('gradient/sample2.jpg', image)\n",
    "\n",
    "    image = np.array(image, dtype=np.float64)\n",
    "    colored_image_lab = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.float64)\n",
    "\n",
    "    for i in range(colored_image_lab.shape[0]):\n",
    "        for j in range(colored_image_lab.shape[1]):\n",
    "            sd = sds[i,j]\n",
    "            weighted_lum = (0.9*image[i, j] + 0.1*sd)\n",
    "            # weighted_lum = image[i, j]\n",
    "            # if image[i, j] - sd > 30.0:\n",
    "            #     print(\"W,S,I:\", weighted_lum, sd, image[i, j])\n",
    "\n",
    "            colored_image_lab[i, j, 0] = image[i, j]\n",
    "            min_lum = np.inf\n",
    "            for color in sampled_colors:\n",
    "                lum = color[0]\n",
    "                distance = calc_distance_val(lum, weighted_lum)\n",
    "\n",
    "                if distance < min_lum:\n",
    "                    min_lum = distance\n",
    "                    # colored_image_lab[i, j, 0] = color[0]\n",
    "                    #print('color: ', np.array([image[i - amt_to_pad, j - amt_to_pad], color[1], color[2]]))\n",
    "                    colored_image_lab[i, j, 1], colored_image_lab[i, j, 2]  = color[1].copy(), color[2].copy()#image_path[int(color[3]), int(color[4])]\n",
    "                else:\n",
    "                    continue\n",
    "            # print(colored_image_lab[i, j])\n",
    "    return colored_image_lab\n",
    "\n",
    "target_image_to_color = cv2.imread('target_image_2.jpg', 0)\n",
    "colored_image_lab = coloring(target_image_to_color, sds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(np.max(colored_image_lab[:,:,1]), np.min(colored_image_lab[:,:,1]))\n",
    "\n",
    "# def coloring(source_image, target_image, sds, sampled_colors, patch_size=5):\n",
    "#     target_image = np.array(target_image, dtype=np.float64)\n",
    "#     colored_image_lab = np.zeros((target_image.shape[0], target_image.shape[1], 3))\n",
    "\n",
    "#     pad_amount = patch_size // 2\n",
    "#     padded_image = np.pad(target_image.copy(), ((pad_amount, pad_amount), (pad_amount, pad_amount)), mode='edge')\n",
    "\n",
    "#     padded_image_src = np.pad(source_image, ((pad_amount, pad_amount), (pad_amount, pad_amount)), mode='edge')\n",
    "    \n",
    "#     print(sds.shape)\n",
    "#     for j in range(pad_amount, padded_image.shape[0]- pad_amount):\n",
    "#         for i in range(pad_amount, padded_image.shape[1] - pad_amount):\n",
    "#             #print(j - pad_amount, i - pad_amount)\n",
    "#             sd = sds[j - pad_amount, i - pad_amount]\n",
    "#             patch = padded_image[j-pad_amount:j+pad_amount+1, i-pad_amount:i+pad_amount+1]\n",
    "\n",
    "#             # weighted_lum = (0.5 * error + 0.5 * sd)\n",
    "            \n",
    "#             min_distance = np.inf\n",
    "#             best_color = None\n",
    "            \n",
    "#             for color in sampled_colors:\n",
    "#                 loc_j, loc_i = int(color[3]), int(color[4])\n",
    "#                 patch_src = padded_image_src[loc_j:loc_j+patch_size, loc_i:loc_i+patch_size]\n",
    "\n",
    "#                 error = np.sum(np.abs(patch_src - patch))\n",
    "\n",
    "#                 # weighted_lum = (0.5 * error + 0.5 * sd)\n",
    "#                 weighted_lum = error\n",
    "                \n",
    "#                 if weighted_lum < min_distance:\n",
    "#                     min_distance = weighted_lum\n",
    "#                     best_color = color\n",
    "            \n",
    "#             if best_color is not None:\n",
    "#                 # print(colored_image_lab[i, j])\n",
    "#                 colored_image_lab[j-pad_amount, i-pad_amount] = np.array([target_image[j-pad_amount, i-pad_amount], best_color[1], best_color[2]])\n",
    "                \n",
    "#     return colored_image_lab\n",
    "\n",
    "# target_image = cv2.imread('target_image_2.jpg', 0)\n",
    "# # target_image = cv2.cvtColor(target_image, cv2.COLOR_BGR2LAB)\n",
    "# target_image_to_color = target_image.copy()\n",
    "\n",
    "# # cv2.imwrite('wo_swatch/target_image_gray.jpg', target_image_to_color)\n",
    "\n",
    "# source_image = source_image_linshift.copy()\n",
    "# source_image_l = source_image[:, :, 0]\n",
    "# colored_image_lab = coloring(source_image_l, target_image_to_color, sds, sampled_colors, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colored_image_lab_uint = np.array(colored_image_lab, dtype=np.uint8)\n",
    "\n",
    "cv2.imwrite('gray_to_color_wo_swatch.jpg', cv2.cvtColor(colored_image_lab_uint, cv2.COLOR_LAB2BGR))\n",
    "# cv2.imwrite('gray_to_color_wo_swatch.jpg', colored_image_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With Swatches\n",
    "def jitter_sampling_swatch(img, image_lab, num_colors, y_add, x_add):\n",
    "    h, w, _ = image_lab.shape\n",
    "    # print(image_lab.shape)\n",
    "    l, a, b = img[:, :, 0].copy(), img[:, :, 1].copy(), img[:, :, 2].copy()\n",
    "\n",
    "    grid_size = int(np.ceil(np.sqrt(num_colors)))\n",
    "    grid_height = h // grid_size\n",
    "    grid_width = w // grid_size\n",
    "    # print(grid_height, grid_width)\n",
    "\n",
    "    sampled_colors = []\n",
    "    locations = []\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            top = i * grid_height\n",
    "            bottom = (i + 1) * grid_height\n",
    "            left = j * grid_width\n",
    "            right = (j + 1) * grid_width\n",
    "\n",
    "            rand_y = random.randint(top, bottom - 1)\n",
    "            rand_x = random.randint(left, right - 1)\n",
    "\n",
    "            locations.append([l[rand_y + y_add, rand_x + x_add], a[rand_y + y_add, rand_x + x_add], b[rand_y + y_add, rand_x + x_add], rand_y + y_add, rand_x + x_add])\n",
    "            # print(rand_y, rand_x, image_lab[rand_y, rand_x])\n",
    "\n",
    "            val = np.array([l[rand_y + y_add, rand_x + x_add], a[rand_y + y_add, rand_x + x_add], b[rand_y + y_add, rand_x + x_add], rand_y + y_add, rand_x + x_add], dtype=np.float64)\n",
    "            sampled_colors.append(val)\n",
    "    \n",
    "    if len(sampled_colors) > num_colors:\n",
    "        sampled_colors = random.sample(sampled_colors, num_colors)\n",
    "\n",
    "    print(locations)\n",
    "    return sampled_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[166, 124, 88, 40, 27], [168, 122, 90, 42, 37], [168, 122, 89, 40, 48], [168, 122, 89, 44, 55], [168, 123, 88, 36, 69], [170, 121, 90, 43, 79], [171, 122, 90, 43, 85], [170, 121, 91, 43, 90], [169, 122, 90, 49, 21], [169, 122, 90, 46, 33], [170, 121, 90, 52, 41], [168, 122, 89, 45, 54], [170, 121, 90, 45, 69], [170, 121, 90, 47, 73], [169, 122, 90, 46, 88], [172, 120, 92, 47, 97], [171, 121, 91, 63, 20], [172, 121, 91, 61, 34], [172, 120, 91, 57, 45], [172, 121, 91, 58, 59], [171, 122, 90, 55, 63], [173, 120, 93, 56, 77], [174, 119, 94, 59, 85], [176, 119, 94, 61, 90], [173, 120, 94, 65, 26], [173, 120, 94, 74, 34], [176, 119, 95, 74, 43], [175, 120, 94, 68, 54], [175, 119, 95, 72, 61], [176, 119, 94, 67, 78], [176, 120, 94, 72, 82], [176, 119, 96, 66, 96], [176, 121, 94, 80, 29], [178, 119, 95, 78, 39], [179, 119, 96, 81, 43], [180, 118, 97, 84, 59], [180, 118, 97, 79, 65], [178, 118, 96, 77, 77], [180, 116, 97, 77, 87], [179, 119, 96, 82, 98], [180, 120, 97, 94, 28], [174, 121, 94, 87, 30], [179, 119, 97, 94, 49], [178, 119, 96, 86, 53], [178, 119, 97, 87, 61], [179, 119, 96, 85, 71], [180, 118, 98, 90, 87], [183, 117, 100, 93, 90], [182, 119, 99, 104, 20], [181, 118, 98, 97, 34], [182, 119, 99, 104, 47], [182, 119, 99, 103, 50], [182, 118, 99, 96, 66], [183, 117, 101, 102, 71], [184, 116, 102, 97, 84], [187, 118, 102, 104, 94], [182, 118, 100, 108, 26], [182, 119, 99, 106, 32], [185, 117, 102, 112, 41], [187, 118, 102, 112, 52], [189, 115, 104, 113, 63], [189, 116, 103, 111, 73], [189, 115, 104, 108, 85], [189, 115, 105, 107, 92]]\n",
      "[[134, 127, 97, 394, 591], [122, 127, 99, 397, 594], [114, 129, 99, 397, 603], [118, 129, 99, 395, 609], [113, 128, 101, 396, 612], [118, 129, 100, 395, 619], [117, 129, 101, 393, 625], [119, 127, 104, 397, 628], [120, 127, 100, 399, 589], [114, 128, 98, 402, 592], [111, 130, 99, 398, 603], [108, 129, 99, 400, 604], [116, 129, 100, 400, 615], [112, 129, 101, 402, 616], [115, 127, 104, 398, 627], [119, 128, 102, 400, 629], [101, 130, 95, 404, 589], [104, 128, 98, 403, 592], [95, 129, 99, 406, 601], [114, 130, 98, 404, 609], [115, 128, 101, 407, 615], [107, 129, 102, 405, 617], [109, 128, 101, 406, 626], [102, 129, 102, 406, 631], [96, 132, 97, 411, 587], [107, 128, 102, 412, 595], [108, 132, 99, 412, 601], [95, 130, 99, 409, 608], [96, 129, 100, 410, 614], [99, 130, 99, 411, 616], [103, 129, 100, 410, 624], [106, 129, 101, 410, 628], [99, 129, 102, 414, 591], [92, 128, 103, 416, 595], [104, 129, 101, 413, 599], [103, 129, 100, 415, 608], [106, 128, 102, 413, 611], [101, 127, 104, 413, 621], [108, 128, 103, 413, 625], [103, 128, 103, 413, 628], [98, 130, 99, 420, 588], [90, 128, 103, 418, 597], [92, 128, 103, 419, 598], [88, 129, 101, 421, 605], [96, 131, 98, 420, 615], [103, 130, 100, 418, 616], [108, 128, 103, 419, 625], [102, 127, 104, 421, 631], [87, 130, 100, 425, 588], [91, 128, 102, 425, 594], [96, 128, 103, 423, 598], [91, 127, 104, 426, 608], [91, 130, 99, 423, 613], [88, 132, 98, 423, 618], [102, 128, 102, 424, 627], [104, 126, 105, 425, 633], [93, 128, 103, 429, 590], [88, 131, 100, 430, 595], [86, 129, 102, 431, 598], [93, 128, 103, 430, 605], [92, 128, 103, 431, 610], [91, 131, 99, 432, 616], [85, 129, 101, 432, 624], [90, 128, 103, 430, 631]]\n",
      "[[40, 117, 133, 153, 531], [26, 117, 142, 158, 538], [41, 124, 132, 155, 546], [64, 118, 153, 154, 552], [68, 118, 143, 156, 561], [61, 114, 149, 153, 567], [16, 124, 127, 157, 572], [49, 113, 147, 153, 581], [20, 117, 139, 165, 536], [9, 122, 133, 165, 540], [77, 106, 165, 162, 549], [83, 106, 163, 167, 551], [74, 114, 151, 162, 559], [27, 121, 133, 166, 567], [17, 124, 134, 166, 574], [28, 116, 139, 165, 583], [17, 122, 130, 172, 530], [28, 111, 144, 174, 538], [118, 105, 165, 168, 548], [89, 108, 161, 168, 552], [42, 115, 147, 168, 561], [20, 124, 133, 171, 568], [25, 115, 142, 173, 575], [30, 110, 145, 173, 585], [19, 118, 137, 179, 534], [14, 118, 136, 181, 538], [19, 120, 135, 178, 545], [66, 107, 162, 179, 552], [104, 101, 169, 180, 559], [42, 114, 147, 183, 569], [64, 115, 148, 180, 572], [45, 105, 153, 182, 579], [15, 120, 133, 189, 532], [19, 115, 139, 187, 541], [98, 101, 169, 188, 546], [170, 88, 189, 186, 557], [162, 90, 188, 191, 558], [77, 102, 162, 192, 571], [36, 116, 143, 192, 574], [18, 120, 135, 187, 579], [57, 107, 156, 196, 535], [8, 122, 132, 200, 540], [45, 109, 152, 202, 544], [60, 105, 159, 195, 553], [54, 107, 157, 199, 561], [108, 94, 175, 200, 567], [126, 93, 178, 202, 572], [38, 112, 147, 202, 583], [14, 118, 136, 212, 530], [7, 124, 130, 210, 537], [12, 120, 135, 211, 548], [69, 107, 159, 209, 555], [86, 104, 164, 205, 562], [82, 105, 165, 210, 566], [114, 93, 177, 210, 573], [21, 118, 139, 204, 580], [6, 124, 131, 221, 532], [21, 113, 140, 220, 538], [6, 124, 131, 221, 546], [3, 126, 130, 219, 551], [6, 128, 130, 220, 558], [49, 109, 155, 218, 568], [134, 92, 182, 213, 575], [127, 101, 170, 217, 579]]\n",
      "[[76, 100, 165, 178, 585], [71, 102, 163, 175, 588], [86, 101, 165, 178, 591], [38, 108, 149, 177, 594], [46, 107, 152, 176, 597], [44, 104, 152, 178, 602], [73, 100, 164, 177, 604], [85, 99, 165, 176, 606], [73, 103, 162, 180, 586], [91, 100, 168, 180, 590], [83, 100, 167, 182, 593], [68, 102, 160, 180, 595], [55, 102, 157, 181, 597], [61, 105, 154, 180, 601], [52, 106, 153, 180, 604], [60, 113, 144, 182, 608], [67, 102, 162, 184, 586], [42, 107, 151, 184, 590], [54, 107, 156, 184, 593], [47, 105, 154, 186, 596], [80, 102, 163, 184, 597], [27, 110, 143, 183, 602], [56, 107, 152, 186, 603], [159, 110, 146, 186, 608], [70, 106, 158, 187, 587], [55, 109, 156, 187, 590], [42, 110, 150, 187, 592], [86, 101, 166, 189, 596], [68, 104, 160, 190, 598], [59, 108, 154, 187, 600], [63, 106, 158, 190, 603], [83, 100, 162, 189, 606], [38, 111, 149, 191, 585], [42, 107, 150, 194, 589], [83, 101, 163, 193, 591], [68, 101, 162, 191, 595], [38, 108, 149, 194, 599], [35, 109, 148, 194, 600], [83, 102, 166, 194, 603], [81, 98, 167, 191, 607], [68, 109, 156, 196, 586], [42, 107, 151, 198, 590], [47, 103, 154, 198, 592], [78, 102, 163, 197, 595], [90, 103, 166, 197, 597], [55, 108, 154, 198, 601], [78, 100, 165, 196, 605], [70, 101, 163, 195, 608], [70, 109, 153, 201, 587], [34, 110, 147, 199, 588], [66, 102, 160, 201, 593], [74, 104, 158, 201, 596], [53, 106, 154, 202, 597], [45, 109, 149, 202, 602], [72, 103, 162, 201, 605], [66, 103, 161, 202, 606], [52, 110, 148, 203, 585], [31, 116, 137, 206, 589], [43, 112, 144, 205, 593], [27, 114, 141, 206, 594], [34, 109, 146, 205, 599], [35, 109, 148, 203, 601], [28, 111, 144, 204, 605], [18, 117, 137, 205, 608]]\n",
      "[[170, 121, 90, 10, 201], [171, 121, 90, 10, 205], [173, 120, 91, 12, 222], [173, 120, 93, 12, 243], [171, 122, 92, 13, 250], [171, 122, 92, 10, 262], [173, 123, 92, 10, 275], [179, 117, 98, 12, 292], [171, 121, 91, 17, 189], [170, 121, 90, 16, 204], [172, 121, 92, 15, 228], [172, 121, 92, 15, 237], [173, 121, 92, 15, 253], [175, 121, 92, 14, 271], [174, 122, 92, 14, 276], [178, 120, 96, 16, 296], [173, 120, 93, 21, 196], [173, 120, 92, 21, 212], [171, 121, 92, 19, 219], [173, 121, 92, 20, 238], [176, 119, 94, 18, 252], [176, 120, 94, 18, 271], [175, 121, 94, 20, 276], [178, 119, 97, 18, 297], [174, 120, 93, 23, 191], [174, 120, 93, 22, 203], [173, 121, 92, 25, 222], [173, 121, 92, 22, 235], [175, 120, 93, 25, 244], [177, 119, 96, 24, 264], [179, 120, 95, 24, 284], [180, 119, 97, 22, 298], [173, 120, 93, 27, 198], [173, 120, 93, 27, 203], [176, 120, 94, 29, 228], [173, 121, 92, 27, 230], [176, 120, 94, 27, 252], [178, 118, 96, 29, 258], [179, 119, 97, 29, 284], [179, 120, 95, 26, 286], [177, 120, 94, 33, 196], [176, 120, 94, 31, 207], [178, 119, 95, 30, 223], [177, 119, 95, 31, 238], [177, 120, 95, 31, 252], [179, 118, 97, 33, 263], [179, 119, 96, 30, 277], [181, 118, 99, 33, 295], [177, 119, 95, 34, 195], [176, 119, 95, 34, 202], [177, 119, 95, 34, 218], [177, 119, 96, 34, 233], [179, 119, 96, 36, 255], [180, 119, 97, 35, 271], [184, 116, 100, 37, 277], [187, 116, 101, 37, 296], [180, 117, 98, 40, 196], [180, 118, 96, 39, 214], [177, 119, 96, 38, 221], [179, 117, 98, 38, 234], [179, 119, 96, 39, 249], [181, 118, 98, 38, 269], [187, 115, 101, 41, 278], [188, 116, 102, 38, 297]]\n"
     ]
    }
   ],
   "source": [
    "# With Swatches\n",
    "\n",
    "#[y1, x1, y2, x2] = [top, left, bottom, right] : sky, water, tree\n",
    "source_swatches = [[35, 20, 115, 105], [393, 586, 439, 636], [150, 530, 222, 590], [175, 585, 212, 611], [10, 188, 49, 307]]#, [215, 170, 250, 225]]\n",
    "\n",
    "def extract_colors(source_image, source_swatch, num_colors):\n",
    "    # padding = window_size//2\n",
    "    y1, x1, y2, x2 = source_swatch\n",
    "    # padded = np.pad(source_image, ((padding, padding), (padding, padding)), mode='edge')\n",
    "    # padded = np.array(padded, dtype=np.float64)\n",
    "    swatch = source_image[y1:y2,x1:x2,:]\n",
    "    colors = jitter_sampling_swatch(source_image, swatch, num_colors, y1, x1)\n",
    "    return colors\n",
    "    \n",
    "# def color_transfer(source_swatch, target_swatch):\n",
    "\n",
    "source_image_path = 'artistic_image.jpg'\n",
    "source_image = cv2.imread(source_image_path)\n",
    "source_image_lab = cv2.cvtColor(source_image, cv2.COLOR_BGR2LAB)\n",
    "target_image = cv2.imread('target_image_2.jpg', 0)\n",
    "\n",
    "list_colors_per_swatch = []\n",
    "for swatch in source_swatches:\n",
    "    list_colors_per_swatch.append(extract_colors(source_image_lab, swatch, 50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_colors_per_swatch_cons = []\n",
    "# list_colors_per_swatch_cons.append(list_colors_per_swatch[0])\n",
    "# list_colors_per_swatch_cons.append(list_colors_per_swatch[2])\n",
    "# print(source_image_lab[153,547])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_ssd_patch(source_patch, target_patch):\n",
    "    return np.sum((source_patch - target_patch) ** 2)\n",
    "\n",
    "def color_transfer(source_image, target_image, target_swatch, target_color_image, colors, window_size=5):\n",
    "    padding = window_size//2\n",
    "\n",
    "    padded_source = np.pad(source_image, ((padding, padding), (padding, padding)), mode='edge')\n",
    "    padded_source = np.array(padded_source, dtype=np.float64)\n",
    "    # print(padded_source.shape)\n",
    "\n",
    "    padded_target = np.pad(target_image, ((padding, padding), (padding, padding)), mode='edge')\n",
    "    padded_target = np.array(padded_target, dtype=np.float64)\n",
    "    # print(padded_target.shape)\n",
    "\n",
    "    target_image = np.array(target_image, dtype=np.float64)\n",
    "    # print(target_image)\n",
    "    # print(padded_target)\n",
    "    # l, a, b = np.zeros((h, w)), np.zeros(h, w), np.zeros(h, w)\n",
    "\n",
    "    y1, x1, y2, x2 = target_swatch\n",
    "    y1 += padding\n",
    "    x1 += padding\n",
    "    y2 += padding\n",
    "    x2 += padding\n",
    "\n",
    "    for y in range(y1, y2):\n",
    "        for x in range(x1, x2):\n",
    "            target_patch = padded_target[y - padding:y + padding+1, x - padding:x + padding+1]\n",
    "            min_ssd = np.inf\n",
    "            #print(target_patch)\n",
    "\n",
    "            best_match_color = None\n",
    "\n",
    "            for color in colors:\n",
    "                s_y, s_x = int(color[3]), int(color[4])\n",
    "                s_y += padding\n",
    "                s_x += padding\n",
    "                source_patch = padded_source[s_y - padding:s_y + padding+1, s_x - padding:s_x + padding+1]\n",
    "\n",
    "                ssd = compute_ssd_patch(source_patch, target_patch)\n",
    "                if ssd < min_ssd:\n",
    "                    min_ssd = ssd\n",
    "                    best_match_color = color\n",
    "            \n",
    "            target_color_image[y-padding, x-padding] = np.array([target_image[y-padding, x-padding], best_match_color[1].copy(), best_match_color[2].copy()])\n",
    "    return target_color_image\n",
    "\n",
    "\n",
    "h, w = target_image.shape\n",
    "l_ch = target_image.copy()\n",
    "a_ch, b_ch = np.zeros((h,w)), np.zeros((h,w))\n",
    "target_color_image = np.dstack((l_ch, a_ch, b_ch))\n",
    "# target_color_image = np.zeros((h, w, 3))\n",
    "\n",
    "target_swatches = [[150, 110, 210, 200], [355, 70, 405, 195], [263, 74, 305, 150], [314, 150, 323, 265], [25, 300, 65, 415]] \n",
    "# target_swatch = [115, 0, 168, 258]\n",
    "# target_swatch = [0, 0, 168, 258]\n",
    "# color = list_colors_per_swatch[2]\n",
    "\n",
    "# color = []\n",
    "# for sublist in list_colors_per_swatch_cons:\n",
    "#     color.extend(sublist)\n",
    "\n",
    "#source_image_lab[:, :, 0] processing to match target_gray image intensity\n",
    "source_img = cv2.imread(source_image_path)\n",
    "source_image_rgb = cv2.cvtColor(source_img, cv2.COLOR_BGR2RGB)\n",
    "source_image_lab = match_images(source_image_rgb, l_ch)\n",
    "\n",
    "source_image_lab_uint = np.array(source_image_lab, dtype=np.uint8)\n",
    "cv2.imwrite('source_image_linshift_swatch.jpg', cv2.cvtColor(source_image_lab_uint, cv2.COLOR_LAB2BGR))\n",
    "\n",
    "for color, target_swatch in zip(list_colors_per_swatch, target_swatches):\n",
    "\n",
    "    target_color_image = color_transfer(source_image_lab[:, :, 0].copy(), l_ch, target_swatch, target_color_image, color)\n",
    "    \n",
    "target_color_image_save = np.array(target_color_image, dtype=np.uint8)\n",
    "\n",
    "cv2.imwrite('target_color_image.jpg', cv2.cvtColor(target_color_image_save, cv2.COLOR_LAB2BGR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_swatch = [65, 132, 90, 170]\n",
    "# color = list_colors_per_swatch_cons[1]\n",
    "\n",
    "# target_color_image = color_transfer(source_image_lab[:, :, 0], target_image, target_swatch, target_color_image, color)\n",
    "\n",
    "# target_color_image_save = np.array(target_color_image, dtype=np.uint8)\n",
    "\n",
    "# cv2.imwrite('target_color_image_stage2.jpg', cv2.cvtColor(target_color_image_save, cv2.COLOR_LAB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[166.0, 124.0, 88.0, 156, 119], [167.0, 124.0, 88.0, 150, 124], [165.0, 124.0, 88.0, 155, 142], [164.0, 124.0, 88.0, 150, 150], [166.0, 124.0, 88.0, 153, 160], [166.0, 124.0, 88.0, 155, 171], [165.0, 124.0, 88.0, 152, 185], [164.0, 124.0, 88.0, 151, 197], [169.0, 124.0, 88.0, 163, 117], [168.0, 124.0, 88.0, 161, 122], [167.0, 124.0, 88.0, 163, 139], [168.0, 124.0, 88.0, 161, 146], [170.0, 124.0, 88.0, 163, 160], [166.0, 124.0, 88.0, 158, 173], [169.0, 124.0, 88.0, 162, 178], [170.0, 124.0, 88.0, 161, 191], [170.0, 124.0, 88.0, 165, 117], [168.0, 124.0, 88.0, 170, 123], [172.0, 124.0, 88.0, 167, 137], [168.0, 124.0, 88.0, 165, 149], [171.0, 124.0, 88.0, 167, 162], [168.0, 124.0, 88.0, 164, 165], [170.0, 124.0, 88.0, 166, 186], [170.0, 124.0, 88.0, 166, 195], [173.0, 124.0, 88.0, 177, 110], [172.0, 124.0, 88.0, 174, 128], [170.0, 124.0, 88.0, 172, 142], [173.0, 124.0, 88.0, 174, 144], [172.0, 124.0, 88.0, 171, 156], [171.0, 124.0, 88.0, 174, 165], [172.0, 124.0, 88.0, 174, 177], [176.0, 124.0, 88.0, 172, 194], [173.0, 124.0, 88.0, 180, 110], [175.0, 124.0, 88.0, 182, 123], [175.0, 124.0, 88.0, 179, 142], [175.0, 124.0, 88.0, 183, 151], [175.0, 124.0, 88.0, 182, 162], [175.0, 124.0, 88.0, 182, 169], [175.0, 124.0, 88.0, 178, 182], [172.0, 124.0, 88.0, 178, 195], [176.0, 124.0, 88.0, 186, 115], [177.0, 124.0, 88.0, 190, 124], [177.0, 124.0, 88.0, 189, 132], [178.0, 124.0, 88.0, 186, 153], [178.0, 124.0, 88.0, 189, 161], [176.0, 124.0, 88.0, 189, 165], [180.0, 124.0, 88.0, 191, 181], [177.0, 124.0, 88.0, 189, 192], [180.0, 124.0, 88.0, 197, 113], [181.0, 124.0, 88.0, 197, 126], [177.0, 124.0, 88.0, 194, 135], [178.0, 124.0, 88.0, 196, 144], [179.0, 124.0, 88.0, 192, 155], [182.0, 124.0, 88.0, 198, 167], [177.0, 124.0, 88.0, 194, 183], [180.0, 124.0, 88.0, 196, 193], [179.0, 124.0, 88.0, 200, 112], [182.0, 124.0, 88.0, 203, 121], [181.0, 124.0, 88.0, 205, 132], [182.0, 124.0, 88.0, 203, 152], [178.0, 124.0, 88.0, 199, 163], [182.0, 124.0, 88.0, 202, 167], [179.0, 124.0, 88.0, 200, 185], [180.0, 124.0, 88.0, 199, 193]]\n",
      "[[118.0, 127.0, 104.0, 356, 74], [117.0, 129.0, 101.0, 355, 85], [97.0, 129.0, 102.0, 360, 102], [119.0, 129.0, 99.0, 355, 119], [139.0, 129.0, 99.0, 357, 144], [143.0, 128.0, 102.0, 356, 145], [117.0, 129.0, 101.0, 356, 167], [142.0, 130.0, 99.0, 359, 185], [123.0, 130.0, 99.0, 365, 74], [116.0, 128.0, 102.0, 364, 88], [91.0, 128.0, 103.0, 362, 108], [138.0, 128.0, 101.0, 365, 125], [122.0, 128.0, 102.0, 363, 132], [108.0, 129.0, 100.0, 364, 155], [128.0, 128.0, 102.0, 365, 174], [139.0, 128.0, 102.0, 361, 178], [127.0, 129.0, 99.0, 371, 83], [109.0, 129.0, 100.0, 367, 95], [121.0, 128.0, 102.0, 371, 108], [140.0, 128.0, 101.0, 367, 115], [113.0, 128.0, 102.0, 371, 130], [107.0, 128.0, 102.0, 367, 147], [104.0, 132.0, 97.0, 369, 171], [114.0, 129.0, 101.0, 369, 178], [136.0, 128.0, 102.0, 376, 76], [137.0, 130.0, 98.0, 375, 88], [130.0, 128.0, 102.0, 377, 105], [124.0, 128.0, 101.0, 376, 115], [110.0, 129.0, 100.0, 377, 131], [93.0, 132.0, 97.0, 377, 149], [123.0, 129.0, 99.0, 375, 170], [110.0, 129.0, 101.0, 373, 186], [118.0, 129.0, 100.0, 379, 70], [128.0, 130.0, 99.0, 381, 98], [141.0, 130.0, 98.0, 382, 105], [108.0, 128.0, 102.0, 380, 116], [129.0, 129.0, 100.0, 383, 140], [137.0, 130.0, 98.0, 380, 146], [96.0, 132.0, 97.0, 383, 169], [103.0, 128.0, 103.0, 382, 183], [81.0, 128.0, 103.0, 387, 75], [105.0, 129.0, 100.0, 390, 88], [132.0, 128.0, 103.0, 385, 109], [89.0, 128.0, 102.0, 390, 123], [136.0, 130.0, 99.0, 386, 132], [131.0, 130.0, 98.0, 390, 152], [130.0, 128.0, 101.0, 386, 163], [134.0, 128.0, 101.0, 385, 179], [109.0, 128.0, 102.0, 395, 75], [119.0, 128.0, 102.0, 391, 85], [124.0, 128.0, 102.0, 396, 107], [103.0, 127.0, 104.0, 393, 126], [104.0, 129.0, 100.0, 395, 136], [133.0, 128.0, 103.0, 396, 147], [129.0, 128.0, 102.0, 395, 165], [91.0, 131.0, 99.0, 394, 179], [96.0, 132.0, 97.0, 400, 79], [123.0, 128.0, 102.0, 397, 95], [138.0, 128.0, 101.0, 397, 114], [110.0, 128.0, 102.0, 401, 115], [95.0, 131.0, 99.0, 400, 143], [105.0, 127.0, 104.0, 402, 156], [108.0, 129.0, 100.0, 398, 160], [120.0, 128.0, 98.0, 399, 189]]\n",
      "[[64.0, 115.0, 147.0, 265, 77], [71.0, 115.0, 147.0, 263, 91], [72.0, 113.0, 147.0, 263, 94], [69.0, 114.0, 149.0, 266, 109], [62.0, 115.0, 147.0, 267, 118], [54.0, 113.0, 147.0, 264, 125], [76.0, 115.0, 147.0, 265, 130], [65.0, 115.0, 147.0, 265, 137], [68.0, 105.0, 153.0, 271, 75], [79.0, 113.0, 147.0, 268, 84], [55.0, 113.0, 147.0, 268, 95], [37.0, 124.0, 132.0, 271, 107], [76.0, 115.0, 147.0, 268, 113], [67.0, 105.0, 153.0, 272, 127], [52.0, 113.0, 147.0, 271, 131], [45.0, 105.0, 153.0, 269, 140], [69.0, 113.0, 147.0, 276, 79], [58.0, 113.0, 147.0, 275, 83], [26.0, 112.0, 147.0, 276, 95], [42.0, 112.0, 147.0, 276, 106], [26.0, 124.0, 127.0, 275, 111], [69.0, 114.0, 149.0, 276, 124], [47.0, 115.0, 147.0, 277, 130], [38.0, 124.0, 132.0, 277, 142], [32.0, 115.0, 142.0, 282, 79], [45.0, 113.0, 147.0, 278, 83], [56.0, 109.0, 152.0, 279, 93], [54.0, 113.0, 147.0, 282, 102], [32.0, 124.0, 127.0, 278, 114], [67.0, 115.0, 147.0, 278, 127], [52.0, 124.0, 132.0, 279, 136], [65.0, 124.0, 132.0, 282, 143], [68.0, 113.0, 147.0, 287, 77], [62.0, 105.0, 153.0, 285, 90], [86.0, 114.0, 149.0, 286, 92], [56.0, 112.0, 147.0, 285, 103], [67.0, 118.0, 153.0, 287, 117], [57.0, 113.0, 147.0, 286, 124], [85.0, 114.0, 149.0, 285, 136], [64.0, 113.0, 147.0, 286, 139], [31.0, 124.0, 132.0, 289, 82], [66.0, 105.0, 153.0, 288, 89], [73.0, 113.0, 147.0, 288, 98], [51.0, 113.0, 147.0, 292, 109], [75.0, 113.0, 147.0, 290, 113], [66.0, 115.0, 147.0, 292, 120], [73.0, 114.0, 149.0, 288, 129], [67.0, 115.0, 147.0, 288, 137], [41.0, 116.0, 139.0, 297, 82], [72.0, 115.0, 147.0, 295, 86], [27.0, 112.0, 147.0, 296, 97], [25.0, 112.0, 147.0, 295, 108], [37.0, 112.0, 147.0, 296, 110], [64.0, 113.0, 147.0, 296, 122], [65.0, 113.0, 147.0, 297, 136], [40.0, 124.0, 132.0, 295, 138], [68.0, 113.0, 147.0, 302, 76], [49.0, 112.0, 147.0, 300, 88], [36.0, 113.0, 147.0, 298, 99], [53.0, 115.0, 142.0, 302, 105], [27.0, 124.0, 127.0, 300, 118], [80.0, 118.0, 143.0, 301, 122], [55.0, 115.0, 148.0, 302, 134], [43.0, 113.0, 147.0, 302, 140]]\n",
      "[[125.0, 100.0, 165.0, 314, 163], [125.0, 100.0, 168.0, 314, 167], [128.0, 100.0, 165.0, 314, 179], [141.0, 100.0, 165.0, 314, 202], [138.0, 100.0, 165.0, 314, 214], [145.0, 110.0, 146.0, 314, 229], [134.0, 110.0, 146.0, 314, 247], [137.0, 110.0, 146.0, 314, 252], [119.0, 100.0, 165.0, 315, 154], [113.0, 100.0, 165.0, 315, 176], [133.0, 100.0, 168.0, 315, 182], [140.0, 110.0, 146.0, 315, 192], [128.0, 100.0, 165.0, 315, 209], [147.0, 110.0, 146.0, 315, 221], [139.0, 100.0, 165.0, 315, 243], [143.0, 100.0, 165.0, 315, 257], [110.0, 100.0, 165.0, 316, 154], [122.0, 100.0, 165.0, 316, 167], [118.0, 100.0, 165.0, 316, 182], [131.0, 100.0, 165.0, 316, 202], [134.0, 110.0, 146.0, 316, 214], [135.0, 100.0, 165.0, 316, 225], [127.0, 100.0, 165.0, 316, 239], [126.0, 100.0, 165.0, 316, 259], [132.0, 100.0, 165.0, 317, 154], [125.0, 100.0, 165.0, 317, 164], [117.0, 100.0, 165.0, 317, 181], [125.0, 100.0, 165.0, 317, 193], [139.0, 110.0, 146.0, 317, 217], [143.0, 100.0, 165.0, 317, 225], [127.0, 100.0, 165.0, 317, 243], [120.0, 100.0, 165.0, 317, 250], [127.0, 100.0, 165.0, 318, 160], [114.0, 100.0, 165.0, 318, 171], [126.0, 100.0, 165.0, 318, 180], [136.0, 100.0, 165.0, 318, 196], [126.0, 100.0, 165.0, 318, 218], [139.0, 110.0, 146.0, 318, 228], [144.0, 110.0, 146.0, 318, 244], [128.0, 100.0, 165.0, 318, 253], [129.0, 100.0, 165.0, 319, 156], [132.0, 100.0, 165.0, 319, 175], [119.0, 100.0, 165.0, 319, 183], [134.0, 100.0, 165.0, 319, 193], [145.0, 110.0, 146.0, 319, 216], [151.0, 110.0, 146.0, 319, 222], [116.0, 100.0, 168.0, 319, 241], [128.0, 100.0, 165.0, 319, 253], [102.0, 100.0, 165.0, 320, 158], [107.0, 100.0, 165.0, 320, 167], [128.0, 100.0, 165.0, 320, 191], [122.0, 100.0, 165.0, 320, 202], [115.0, 100.0, 165.0, 320, 208], [119.0, 100.0, 165.0, 320, 232], [159.0, 110.0, 146.0, 320, 243], [129.0, 100.0, 165.0, 320, 257], [88.0, 100.0, 165.0, 321, 161], [106.0, 100.0, 165.0, 321, 173], [92.0, 100.0, 165.0, 321, 191], [117.0, 100.0, 165.0, 321, 198], [107.0, 100.0, 165.0, 321, 218], [119.0, 100.0, 165.0, 321, 230], [88.0, 100.0, 165.0, 321, 240], [104.0, 100.0, 165.0, 321, 251]]\n",
      "[[136.0, 121.0, 90.0, 28, 301], [137.0, 121.0, 90.0, 25, 321], [133.0, 121.0, 90.0, 28, 338], [134.0, 121.0, 90.0, 28, 348], [134.0, 121.0, 90.0, 26, 357], [133.0, 121.0, 90.0, 29, 374], [133.0, 121.0, 90.0, 26, 389], [132.0, 121.0, 90.0, 29, 405], [135.0, 121.0, 90.0, 30, 303], [134.0, 121.0, 90.0, 30, 323], [134.0, 121.0, 90.0, 31, 332], [139.0, 121.0, 90.0, 33, 355], [134.0, 121.0, 90.0, 32, 365], [137.0, 121.0, 90.0, 34, 371], [136.0, 121.0, 90.0, 33, 390], [134.0, 121.0, 90.0, 31, 411], [136.0, 121.0, 90.0, 36, 304], [137.0, 121.0, 90.0, 36, 314], [136.0, 121.0, 90.0, 36, 330], [136.0, 121.0, 90.0, 38, 353], [136.0, 121.0, 90.0, 35, 358], [136.0, 121.0, 90.0, 35, 371], [136.0, 121.0, 90.0, 36, 392], [135.0, 121.0, 90.0, 37, 411], [135.0, 121.0, 90.0, 43, 311], [137.0, 121.0, 90.0, 43, 319], [136.0, 121.0, 90.0, 43, 338], [138.0, 121.0, 90.0, 41, 350], [136.0, 121.0, 90.0, 41, 362], [134.0, 121.0, 90.0, 40, 378], [136.0, 121.0, 90.0, 43, 386], [138.0, 121.0, 90.0, 44, 399], [140.0, 121.0, 90.0, 48, 304], [137.0, 121.0, 90.0, 47, 321], [137.0, 121.0, 90.0, 47, 341], [137.0, 121.0, 90.0, 49, 350], [139.0, 121.0, 90.0, 46, 359], [137.0, 121.0, 90.0, 47, 374], [137.0, 121.0, 90.0, 48, 392], [137.0, 121.0, 90.0, 47, 403], [138.0, 121.0, 90.0, 53, 306], [140.0, 121.0, 90.0, 51, 314], [137.0, 121.0, 90.0, 51, 329], [138.0, 121.0, 90.0, 52, 355], [137.0, 121.0, 90.0, 50, 356], [137.0, 121.0, 90.0, 50, 383], [138.0, 121.0, 90.0, 53, 395], [138.0, 121.0, 90.0, 51, 401], [139.0, 121.0, 90.0, 56, 306], [140.0, 121.0, 90.0, 58, 325], [140.0, 121.0, 90.0, 58, 337], [139.0, 121.0, 90.0, 56, 352], [140.0, 121.0, 90.0, 57, 360], [140.0, 121.0, 90.0, 59, 370], [140.0, 121.0, 90.0, 55, 393], [141.0, 121.0, 90.0, 57, 402], [141.0, 121.0, 90.0, 62, 303], [142.0, 121.0, 90.0, 64, 321], [141.0, 121.0, 90.0, 60, 334], [141.0, 121.0, 90.0, 64, 350], [138.0, 121.0, 90.0, 60, 365], [140.0, 121.0, 90.0, 61, 382], [142.0, 121.0, 90.0, 64, 391], [138.0, 121.0, 90.0, 61, 410]]\n"
     ]
    }
   ],
   "source": [
    "src_swatches = [[150, 110, 210, 200], [355, 70, 405, 195], [263, 74, 305, 150], [314, 150, 323, 265], [25, 300, 65, 415]] \n",
    "src_colors = []\n",
    "\n",
    "for swatch in src_swatches:\n",
    "    color = extract_colors(target_color_image, swatch, 50)\n",
    "    src_colors.extend(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imwrite('target_sample.jpg', cv2.cvtColor(np.array(target_color_image, dtype=np.uint8), cv2.COLOR_LAB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_swatch = [0, 0, 471, 600]\n",
    "target_color_image = color_transfer(target_color_image[:, :, 0], target_color_image[:, :, 0], target_swatch, target_color_image, src_colors)\n",
    "\n",
    "target_color_image_save = np.array(target_color_image, dtype=np.uint8)\n",
    "\n",
    "cv2.imwrite('target_color_image_stage3.jpg', cv2.cvtColor(target_color_image_save, cv2.COLOR_LAB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('target_image_2.jpg', 0)\n",
    "cv2.imwrite('target_image.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shadow map is generated\n",
      "\n",
      "Shadow Image generated with lambda 0.99 and 1.3 is generated\n",
      "\n",
      "Bilateral Filter output is generated\n",
      "\n",
      "(438, 640)\n",
      "Edge map output is generated\n",
      "\n",
      "Line draft image is generated\n",
      "\n",
      "Line draft image is generated\n",
      "\n",
      "Line draft image is generated\n",
      "\n",
      "Chromatic map is generated\n",
      "\n",
      "Shadow image is generated\n",
      "\n",
      "Shadow image is generated\n",
      "\n",
      "Shadow image is generated\n",
      "\n",
      "Shadow image with corrected saturation is generated\n",
      "\n",
      "Shadow image with corrected saturation is generated\n",
      "\n",
      "Shadow image with corrected saturation is generated\n",
      "\n",
      "Final artistic image is generated\n",
      "\n",
      "Final artistic image is generated\n",
      "\n",
      "Final artistic image is generated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Ablations ###\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "path = 'Experiment_1/'\n",
    "path2 = 'ablation/'\n",
    "print('')\n",
    "\n",
    "img_bgr = cv2.imread(path + 'source.jpg') #Image is being read in BGR color palette\n",
    "img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "img_gray = cv2.imread(path + 'source.jpg', 0)\n",
    "\n",
    "\n",
    "#1.1.1 Shadow-Map Generation\n",
    "\n",
    "#RGB to HSI\n",
    "\n",
    "img_np = np.asarray(img)\n",
    "\n",
    "h, w, c = img_np.shape\n",
    "\n",
    "I = np.zeros((h, w, 1))\n",
    "V1 = np.zeros((h, w, 1))\n",
    "V2 = np.zeros((h, w, 1))\n",
    "S = np.zeros((h, w, 1))\n",
    "H = np.zeros((h, w, 1))\n",
    "\n",
    "hsi_mat = np.array([[1/3, 1/3, 1/3], [-(np.sqrt(6))/6, -(np.sqrt(6))/6, (np.sqrt(6))/3], [(1/np.sqrt(6)), -(2/np.sqrt(6)), 0]]) #Eqn 1\n",
    "\n",
    "for y in range(h):\n",
    "    for x in range(w):\n",
    "        rgb = img_np[y][x]\n",
    "        rgb = rgb.reshape((3, 1))\n",
    "        out = np.matmul(hsi_mat, rgb)\n",
    "        I[y][x] = out[0][0]\n",
    "        V1[y][x] = out[1][0]\n",
    "        V2[y][x] = out[2][0]\n",
    "        S[y][x] = np.sqrt((np.square(V1[y][x])) + np.square(V2[y][x])) #Eqn 2\n",
    "        if V1[y][x] != 1:\n",
    "            if V1[y][x] == 0 and V2[y][x] == 0:\n",
    "                H[y][x] = 0\n",
    "                continue\n",
    "            elif V1[y][x] == 0:\n",
    "                H[y][x] = 0\n",
    "                continue\n",
    "            H[y][x] = np.arctan((V2[y][x])/V1[y][x]) #Eqn 3\n",
    "\n",
    "H_norm = (H - np.min(H)) / (np.max(H) - np.min(H))\n",
    "I_norm = (I - np.min(I)) / (np.max(I) - np.min(I))\n",
    "\n",
    "#Computing r-map\n",
    "r_map = (H_norm + 1) / (I_norm + 1) #Eqn 4\n",
    "\n",
    "r_map_scaled = 255 * ((r_map - np.min(r_map)) / (np.max(r_map) - np.min(r_map)))\n",
    "\n",
    "\n",
    "#Threshold for Shadow Map\n",
    "\n",
    "P = {}\n",
    "\n",
    "for y in range(r_map_scaled.shape[0]):\n",
    "    for x in range(r_map_scaled.shape[1]):\n",
    "        keys_list = P.keys()\n",
    "        if int(r_map_scaled[y][x]) in keys_list:\n",
    "            P[int(r_map_scaled[y][x])] += 1\n",
    "        else:\n",
    "            P[int(r_map_scaled[y][x])] = 1\n",
    "\n",
    "for key in P.keys():\n",
    "    P[key] = P[key] / (h * w)\n",
    "\n",
    "T_dict = {}\n",
    "\n",
    "for t in range(0, 256):\n",
    "    W1, W2 = 0, 0\n",
    "    for i in range(0, t+1):\n",
    "        if i in P.keys():\n",
    "            W1 += P[i]\n",
    "    for i in range(t+1, 256):\n",
    "        if i in P.keys():\n",
    "            W2 += P[i]\n",
    "\n",
    "    mu1, mu2 = 0, 0\n",
    "    for i in range(0, t+1):\n",
    "        if i in P.keys():\n",
    "            mu1 += (i * P[i]) / W1\n",
    "    for i in range(t+1, 256):\n",
    "        if i in P.keys():\n",
    "            mu2 += (i * P[i]) / W2\n",
    "\n",
    "    t1, t2 = 0, 0\n",
    "    for i in range(0, t+1):\n",
    "        if i in P.keys():\n",
    "            t1 += P[i] * ((i - mu1) ** 2)\n",
    "    for i in range(t+1, 256):\n",
    "        if i in P.keys():\n",
    "            t2 += P[i] * ((i - mu2) ** 2)\n",
    "\n",
    "    T_dict[t] = t1+t2\n",
    "\n",
    "\n",
    "lt = []\n",
    "for key in T_dict.keys():\n",
    "    lt.append(T_dict[key])\n",
    "\n",
    "T = lt.index(min(lt))\n",
    "\n",
    "\n",
    "#Shadow map\n",
    "\n",
    "s = np.where(r_map_scaled > T, 1, 0)\n",
    "s_inv = np.where(r_map_scaled > T, 0, 1)\n",
    "cv2.imwrite(path2 + f'shadow_map_{T}.jpg', s_inv * 255)\n",
    "\n",
    "s = np.where(r_map_scaled > T-30, 1, 0)\n",
    "s_inv_test = np.where(r_map_scaled > T-30, 0, 1)\n",
    "cv2.imwrite(path2 + f'shadow_map_{T-30}.jpg', s_inv_test * 255)\n",
    "\n",
    "s = np.where(r_map_scaled > T+30, 1, 0)\n",
    "s_inv_test = np.where(r_map_scaled > T+30, 0, 1)\n",
    "cv2.imwrite(path2 + f'shadow_map_{T+30}.jpg', s_inv_test * 255)\n",
    "\n",
    "print('Shadow map is generated\\n')\n",
    "\n",
    "\n",
    "#Shadow Image\n",
    "\n",
    "lmd_1 = 0.8\n",
    "SI_1 = np.where(s_inv == 0, lmd_1 * img_bgr + (1 - lmd_1) * s_inv, img_bgr)\n",
    "\n",
    "cv2.imwrite(path2 + f'shadow_image_lmb_{lmd_1}.jpg', SI_1)\n",
    "\n",
    "lmd_1 = 0\n",
    "SI_1_test = np.where(s_inv == 0, lmd_1 * img_bgr + (1 - lmd_1) * s_inv, img_bgr)\n",
    "\n",
    "cv2.imwrite(path2 + f'shadow_image_lmb_{lmd_1}.jpg', SI_1_test)\n",
    "\n",
    "lmd_1 = 0.99\n",
    "SI_1_test = np.where(s_inv == 0, lmd_1 * img_bgr + (1 - lmd_1) * s_inv, img_bgr)\n",
    "\n",
    "cv2.imwrite(path2 + f'shadow_image_lmb_{lmd_1}.jpg', SI_1_test)\n",
    "\n",
    "lmd_2 = 1.3\n",
    "SI_2 = np.where(s_inv == 0, lmd_2 * img_bgr + (1 - lmd_2) * s_inv, img_bgr)\n",
    "\n",
    "cv2.imwrite(path2 + 'shadow_image_lmd_1.3.jpg', SI_2)\n",
    "\n",
    "print(f'Shadow Image generated with lambda {lmd_1} and {lmd_2} is generated\\n')\n",
    "\n",
    "\n",
    "\n",
    "#1.1.2 Line Draft Generation\n",
    "\n",
    "\n",
    "#Bilateral Filtering\n",
    "\n",
    "def bilateral_filter(image, diameter, sigma_color, sigma_space):\n",
    "    filtered_image = np.zeros_like(image)\n",
    "    height, width = image.shape\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            weighted_sum = 0\n",
    "            normalization = 0\n",
    "\n",
    "            for i in range(-diameter // 2, diameter // 2 + 1):\n",
    "                for j in range(-diameter // 2, diameter // 2 + 1):\n",
    "                    neighbor_y = y + i\n",
    "                    neighbor_x = x + j\n",
    "\n",
    "                    if 0 <= neighbor_y < height and 0 <= neighbor_x < width:\n",
    "                        color_difference = float(image[neighbor_y, neighbor_x]) - float(image[y, x])\n",
    "\n",
    "                        intensity_weight = np.exp(-np.square(color_difference) / (2 * sigma_color * sigma_color))\n",
    "                        spatial_weight = np.exp(-(np.square(i) + np.square(j)) / (2 * sigma_space * sigma_space))\n",
    "\n",
    "                        weight = intensity_weight * spatial_weight\n",
    "\n",
    "                        weighted_sum += weight * image[neighbor_y, neighbor_x]\n",
    "                        normalization += weight\n",
    "\n",
    "            filtered_image[y, x] = weighted_sum / normalization\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "\n",
    "diameter = 5\n",
    "sigma_colors = [50]\n",
    "sigma_spaces = [50]\n",
    "bil_img = None\n",
    "for sigma_color in sigma_colors:\n",
    "    for sigma_space in sigma_spaces:\n",
    "        filtered_image = bilateral_filter(img_gray, diameter, sigma_color, sigma_space)\n",
    "        filtered_image = np.array(filtered_image, dtype=np.uint8)\n",
    "        if sigma_color == 50 and sigma_space == 50:\n",
    "            bil_img = filtered_image\n",
    "        cv2.imwrite(path2 + f'bilateral_filter_output_{diameter}_{sigma_color}_{sigma_space}.jpg', filtered_image)\n",
    "        print('Bilateral Filter output is generated\\n')\n",
    "\n",
    "bil_opencv = cv2.bilateralFilter(img_gray.copy(), 7, 50.0, 50.0)\n",
    "cv2.imwrite(path2 + 'bilateral_filter_output_opencv.jpg', bil_opencv)\n",
    "\n",
    "\n",
    "# Edge Detection\n",
    "\n",
    "#Best sigma_color, Best sigma_space \n",
    "bil_img = cv2.imread(path2 + 'bilateral_filter_output_5_50_50.jpg', 0)\n",
    "print(bil_img.shape)\n",
    "\n",
    "sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "sobel_y = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
    "\n",
    "padded_image = np.pad(bil_img, ((1, 1), (1, 1)), mode='edge')\n",
    "\n",
    "gradient_x = np.zeros_like(bil_img, dtype=np.float32)\n",
    "gradient_y = np.zeros_like(bil_img, dtype=np.float32)\n",
    "\n",
    "for y in range(bil_img.shape[0]):\n",
    "    for x in range(bil_img.shape[1]):\n",
    "        gradient_x[y, x] = np.sum(padded_image[y:y+3, x:x+3] * sobel_x)\n",
    "        gradient_y[y, x] = np.sum(padded_image[y:y+3, x:x+3] * sobel_y)\n",
    "\n",
    "edge_map = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "\n",
    "cv2.imwrite(path2 + 'edge_map.jpg', edge_map)\n",
    "print('Edge map output is generated\\n')\n",
    "\n",
    "\n",
    "#Line Draft using Threshold\n",
    "\n",
    "ld_thresh = 130\n",
    "\n",
    "line_draft = np.where(edge_map >= ld_thresh, 1, 0)\n",
    "\n",
    "line_draft_inv = 255 * np.where(edge_map >= ld_thresh, 0, 1)\n",
    "\n",
    "cv2.imwrite(path2 + 'line_draft_inv.jpg', line_draft_inv)\n",
    "print('Line draft image is generated\\n')\n",
    "\n",
    "\n",
    "ld_thresh = 100\n",
    "\n",
    "line_draft_test = np.where(edge_map >= ld_thresh, 1, 0)\n",
    "\n",
    "line_draft_inv_test = 255 * np.where(edge_map >= ld_thresh, 0, 1)\n",
    "\n",
    "cv2.imwrite(path2 + f'line_draft_inv_{ld_thresh}.jpg', line_draft_inv_test)\n",
    "print('Line draft image is generated\\n')\n",
    "\n",
    "ld_thresh = 170\n",
    "\n",
    "line_draft_test = np.where(edge_map >= ld_thresh, 1, 0)\n",
    "\n",
    "line_draft_inv_test = 255 * np.where(edge_map >= ld_thresh, 0, 1)\n",
    "\n",
    "cv2.imwrite(path2 + f'line_draft_inv_{ld_thresh}.jpg', line_draft_inv_test)\n",
    "print('Line draft image is generated\\n')\n",
    "\n",
    "\n",
    "#1.2 Color Adjustment Step\n",
    "\n",
    "lab_img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "l, a, b = lab_img[:,:,0], lab_img[:,:,1], lab_img[:,:,2]\n",
    "l_mid = np.int8(60)\n",
    "\n",
    "neutral_l = np.ones((h, w), dtype=np.uint8) * l_mid\n",
    "\n",
    "chromatic_map = np.stack((neutral_l, a, b), axis = -1)\n",
    "\n",
    "chromatic_map_rgb = cv2.cvtColor(chromatic_map, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "cv2.imwrite(path + 'chromatic_map.jpg', cv2.cvtColor(chromatic_map, cv2.COLOR_LAB2BGR))\n",
    "print('Chromatic map is generated\\n')\n",
    "\n",
    "\n",
    "#SI in BGR\n",
    "\n",
    "SI = SI_1.copy()\n",
    "rho = 0.01 #[0.005, 0.2]\n",
    "\n",
    "SI = np.array(SI, dtype=np.uint8)\n",
    "\n",
    "SI = cv2.cvtColor(SI, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "SI_prime = SI * ((1 + np.tanh(rho * (chromatic_map_rgb - 128))) / 2)\n",
    "SI_prime = np.array(SI_prime, dtype=np.uint8)\n",
    "\n",
    "cv2.imwrite(path2 + 'shadow_image_color_enhanced.jpg', cv2.cvtColor(SI_prime, cv2.COLOR_RGB2BGR))\n",
    "print('Shadow image is generated\\n')\n",
    "\n",
    "\n",
    "SI = SI_1.copy()\n",
    "rho = 0.005 #[0.005, 0.2]\n",
    "\n",
    "SI = np.array(SI, dtype=np.uint8)\n",
    "\n",
    "SI = cv2.cvtColor(SI, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "SI_prime_test = SI * ((1 + np.tanh(rho * (chromatic_map_rgb - 128))) / 2)\n",
    "SI_prime_test = np.array(SI_prime_test, dtype=np.uint8)\n",
    "\n",
    "cv2.imwrite(path2 + f'shadow_image_color_enhanced_{rho}.jpg', cv2.cvtColor(SI_prime_test, cv2.COLOR_RGB2BGR))\n",
    "print('Shadow image is generated\\n')\n",
    "\n",
    "SI = SI_1.copy()\n",
    "rho = 0.2 #[0.005, 0.2]\n",
    "\n",
    "SI = np.array(SI, dtype=np.uint8)\n",
    "\n",
    "SI = cv2.cvtColor(SI, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "SI_prime_test = SI * ((1 + np.tanh(rho * (chromatic_map_rgb - 128))) / 2)\n",
    "SI_prime_test = np.array(SI_prime_test, dtype=np.uint8)\n",
    "\n",
    "cv2.imwrite(path2 + f'shadow_image_color_enhanced_{rho}.jpg', cv2.cvtColor(SI_prime_test, cv2.COLOR_RGB2BGR))\n",
    "print('Shadow image is generated\\n')\n",
    "\n",
    "\n",
    "#Saturation Correction\n",
    "\n",
    "saturation_scale = 1.3\n",
    "\n",
    "SI_prime_HSV = cv2.cvtColor(SI_prime, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "H = SI_prime_HSV[:, :, 0]\n",
    "S = SI_prime_HSV[:, :, 1]\n",
    "V = SI_prime_HSV[:, :, 2]\n",
    "\n",
    "S_corrected = np.array(np.round(255 * ((S - np.min(S)) / (np.max(S) - np.min(S))))).astype(int)\n",
    "\n",
    "S_corrected = S_corrected * saturation_scale\n",
    "S_corrected = np.clip(S_corrected, 0, 255)\n",
    "\n",
    "S_corrected = np.array(S_corrected, dtype=np.uint8)\n",
    "\n",
    "SI_corrected = np.stack((H, S_corrected, V), axis = -1) #Why not S\n",
    "\n",
    "SI_corrected_RGB = cv2.cvtColor(SI_corrected, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "cv2.imwrite(path2 + 'shadow_image_corrected.jpg', cv2.cvtColor(SI_corrected, cv2.COLOR_HSV2BGR))\n",
    "print('Shadow image with corrected saturation is generated\\n')\n",
    "\n",
    "\n",
    "saturation_scale = 1\n",
    "\n",
    "SI_prime_HSV = cv2.cvtColor(SI_prime, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "H = SI_prime_HSV[:, :, 0]\n",
    "S = SI_prime_HSV[:, :, 1]\n",
    "V = SI_prime_HSV[:, :, 2]\n",
    "\n",
    "S_corrected = np.array(np.round(255 * ((S - np.min(S)) / (np.max(S) - np.min(S))))).astype(int)\n",
    "\n",
    "S_corrected = S_corrected * saturation_scale\n",
    "S_corrected = np.clip(S_corrected, 0, 255)\n",
    "\n",
    "S_corrected = np.array(S_corrected, dtype=np.uint8)\n",
    "\n",
    "SI_corrected = np.stack((H, S_corrected, V), axis = -1) #Why not S\n",
    "\n",
    "cv2.imwrite(path2 + f'shadow_image_corrected_{saturation_scale}.jpg', cv2.cvtColor(SI_corrected, cv2.COLOR_HSV2BGR))\n",
    "print('Shadow image with corrected saturation is generated\\n')\n",
    "\n",
    "saturation_scale = 2\n",
    "\n",
    "SI_prime_HSV = cv2.cvtColor(SI_prime, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "H = SI_prime_HSV[:, :, 0]\n",
    "S = SI_prime_HSV[:, :, 1]\n",
    "V = SI_prime_HSV[:, :, 2]\n",
    "\n",
    "S_corrected = np.array(np.round(255 * ((S - np.min(S)) / (np.max(S) - np.min(S))))).astype(int)\n",
    "\n",
    "S_corrected = S_corrected * saturation_scale\n",
    "S_corrected = np.clip(S_corrected, 0, 255)\n",
    "\n",
    "S_corrected = np.array(S_corrected, dtype=np.uint8)\n",
    "\n",
    "SI_corrected = np.stack((H, S_corrected, V), axis = -1) #Why not S\n",
    "\n",
    "cv2.imwrite(path2 + f'shadow_image_corrected_{saturation_scale}.jpg', cv2.cvtColor(SI_corrected, cv2.COLOR_HSV2BGR))\n",
    "print('Shadow image with corrected saturation is generated\\n')\n",
    "\n",
    "\n",
    "#Artistic Enhanced Image\n",
    "beta = 0.7 #[0, 1]\n",
    "\n",
    "line_draft_inv_3d = np.stack([line_draft_inv, line_draft_inv, line_draft_inv], axis = -1) \n",
    "\n",
    "artistic_image = np.where(line_draft_inv_3d == 0, beta * SI_corrected_RGB, SI_corrected_RGB)\n",
    "\n",
    "artistic_image = np.array(artistic_image, dtype=np.uint8)\n",
    "\n",
    "cv2.imwrite(path2 + 'artistic_image.jpg', cv2.cvtColor(artistic_image, cv2.COLOR_RGB2BGR))\n",
    "print('Final artistic image is generated\\n')\n",
    "\n",
    "beta = 0 #[0, 1]\n",
    "\n",
    "line_draft_inv_3d = np.stack([line_draft_inv, line_draft_inv, line_draft_inv], axis = -1) \n",
    "\n",
    "artistic_image = np.where(line_draft_inv_3d == 0, beta * SI_corrected_RGB, SI_corrected_RGB)\n",
    "\n",
    "artistic_image = np.array(artistic_image, dtype=np.uint8)\n",
    "\n",
    "cv2.imwrite(path2 + f'artistic_image_{beta}.jpg', cv2.cvtColor(artistic_image, cv2.COLOR_RGB2BGR))\n",
    "print('Final artistic image is generated\\n')\n",
    "\n",
    "\n",
    "beta = 1 #[0, 1]\n",
    "\n",
    "line_draft_inv_3d = np.stack([line_draft_inv, line_draft_inv, line_draft_inv], axis = -1) \n",
    "\n",
    "artistic_image = np.where(line_draft_inv_3d == 0, beta * SI_corrected_RGB, SI_corrected_RGB)\n",
    "\n",
    "artistic_image = np.array(artistic_image, dtype=np.uint8)\n",
    "\n",
    "cv2.imwrite(path2 + f'artistic_image_{beta}.jpg', cv2.cvtColor(artistic_image, cv2.COLOR_RGB2BGR))\n",
    "print('Final artistic image is generated\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2\n",
      "Target image with colors and without swatches generated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "image_path = input('Give folder name containing the source image and target image: ')\n",
    "\n",
    "path = str(image_path) + '/'\n",
    "print('')\n",
    "\n",
    "def compute_ssd_patch(source_patch, target_patch):\n",
    "    return np.sum((source_patch - target_patch) ** 2)\n",
    "\n",
    "def are_images_equal(image1, image2):\n",
    "    if image1.shape != image2.shape:\n",
    "        raise ValueError(\"Images must have the same shape for MSE calculation.\")\n",
    "\n",
    "    squared_diff = np.square(image1 - image2)\n",
    "    mse = np.mean(squared_diff)\n",
    "    return mse\n",
    "\n",
    "#3 Color Transfer\n",
    "\n",
    "#Global transfer\n",
    "\n",
    "def linshift_match_images(source_image, target_image):\n",
    "    source_image_lab = cv2.cvtColor(source_image, cv2.COLOR_RGB2LAB)\n",
    "    source_image_l_norm = source_image_lab[:, :, 0]\n",
    "    a, b = source_image_lab[:, :, 1], source_image_lab[:, :, 2]\n",
    "    source_image_l_norm = np.array(source_image_l_norm, dtype=np.float64) / 255.0\n",
    "\n",
    "    target_image_wo_norm = target_image.copy()\n",
    "\n",
    "    target_image_norm = np.array(target_image_wo_norm, dtype=np.float64) / 255.0\n",
    "\n",
    "    mu_target = np.mean(target_image_norm)\n",
    "    sigma_target = np.std(target_image_norm)\n",
    "\n",
    "    mu_source = np.mean(source_image_l_norm)\n",
    "    sigma_source = np.std(source_image_l_norm)\n",
    "\n",
    "    source_image_l_linshift_pre = ((sigma_target/sigma_source) * (source_image_l_norm - mu_source)) + mu_target\n",
    "\n",
    "    source_image_l_linshift = (source_image_l_linshift_pre - np.min(source_image_l_linshift_pre)) / (np.max(source_image_l_linshift_pre) - np.min(source_image_l_linshift_pre))\n",
    "\n",
    "    source_image_l_linshift *= 255.0\n",
    "    source_image_l_linshift = np.clip(source_image_l_linshift, 0, 255)\n",
    "\n",
    "    source_image_linshift = np.dstack((source_image_l_linshift, a, b))\n",
    "\n",
    "    return source_image_linshift\n",
    "\n",
    "source_img = cv2.imread(path + 'artistic_image.jpg')\n",
    "target_img_bgr = cv2.imread(path + 'target_image2.jpg')\n",
    "target_img_lab = cv2.cvtColor(target_img_bgr, cv2.COLOR_BGR2LAB)\n",
    "target_img = target_img_lab[:, :, 0]\n",
    "\n",
    "source_img_rgb = cv2.cvtColor(source_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "source_image_linshift = linshift_match_images(source_img_rgb, target_img)\n",
    "\n",
    "source_image_linshift_uint = np.array(source_image_linshift, dtype=np.uint8)\n",
    "\n",
    "#cv2.imwrite('source_image_linshift.jpg', cv2.cvtColor(source_image_linshift_uint, cv2.COLOR_LAB2BGR))\n",
    "\n",
    "\n",
    "#jitter sampling\n",
    "\n",
    "def jitter_sampling(image_lab, num_colors):\n",
    "    h, w, _ = image_lab.shape\n",
    "    image_lab = np.array(image_lab, dtype=np.float64)\n",
    "\n",
    "    l, a, b = image_lab[:, :, 0].copy(), image_lab[:, :, 1].copy(), image_lab[:, :, 2].copy()\n",
    "\n",
    "    grid_size = int(np.ceil(np.sqrt(num_colors)))\n",
    "    grid_height = h // grid_size\n",
    "    grid_width = w // grid_size\n",
    "\n",
    "    sampled_colors = []\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            top = i * grid_height\n",
    "            bottom = (i + 1) * grid_height\n",
    "            left = j * grid_width\n",
    "            right = (j + 1) * grid_width\n",
    "\n",
    "            rand_y = random.randint(top, bottom - 1)\n",
    "            rand_x = random.randint(left, right - 1)\n",
    "\n",
    "            val = np.array([l[rand_y, rand_x], a[rand_y, rand_x], b[rand_y, rand_x], rand_y, rand_x], dtype=np.float64)\n",
    "            sampled_colors.append(val)\n",
    "    \n",
    "    if len(sampled_colors) > num_colors:\n",
    "        sampled_colors = random.sample(sampled_colors, num_colors)\n",
    "\n",
    "    return sampled_colors\n",
    "\n",
    "image_path = source_image_linshift.copy()\n",
    "num_colors = 200 #As mentioned in paper\n",
    "\n",
    "sampled_colors = jitter_sampling(image_path, num_colors)\n",
    "sampled_colors = np.array(sampled_colors, dtype=np.float64)\n",
    "\n",
    "\n",
    "def calc_distance_val(p1, p2):\n",
    "    return abs(float(p1) - float(p2))\n",
    "\n",
    "\n",
    "def compute_sd(image, neighborhood_size=5):\n",
    "    amt_to_pad = (neighborhood_size - 1) // 2\n",
    "    y, x = image.shape\n",
    "    sds = np.zeros((y, x))\n",
    "\n",
    "    padded = np.pad(image, ((amt_to_pad, amt_to_pad), (amt_to_pad, amt_to_pad)), mode='edge')\n",
    "    padded = np.array(padded, dtype=np.float64)\n",
    "\n",
    "    for i in range(amt_to_pad, y + amt_to_pad):\n",
    "        for j in range(amt_to_pad, x + amt_to_pad):\n",
    "            region = padded[i - amt_to_pad:i + amt_to_pad + 1, j - amt_to_pad:j + amt_to_pad + 1]\n",
    "            sd = np.std(region)\n",
    "            sds[i - amt_to_pad, j - amt_to_pad] = sd\n",
    "    return sds\n",
    "\n",
    "# target_img = cv2.imread(path + 'target_image2.jpg', 0)\n",
    "sds = compute_sd(target_img, 5)\n",
    "\n",
    "\n",
    "# def coloring(image, sds):\n",
    "#     image = np.array(image, dtype=np.float64)\n",
    "#     colored_image_lab = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.float64)\n",
    "\n",
    "#     for i in range(colored_image_lab.shape[0]):\n",
    "#         for j in range(colored_image_lab.shape[1]):\n",
    "#             sd = sds[i,j]\n",
    "#             weighted_lum = (0.9*image[i, j] + 0.1*sd)\n",
    "\n",
    "#             colored_image_lab[i, j, 0] = image[i, j]\n",
    "#             min_lum = np.inf\n",
    "#             for color in sampled_colors:\n",
    "#                 lum = color[0]\n",
    "#                 distance = calc_distance_val(lum, weighted_lum)\n",
    "\n",
    "#                 if distance < min_lum:\n",
    "#                     min_lum = distance\n",
    "#                     colored_image_lab[i, j, 1], colored_image_lab[i, j, 2]  = color[1].copy(), color[2].copy()\n",
    "#                 else:\n",
    "#                     continue\n",
    "#     return colored_image_lab\n",
    "\n",
    "def coloring(source_image, target_image, target_swatch, target_color_image, colors, sds, window_size=5):\n",
    "    padding = window_size//2\n",
    "    print(padding)\n",
    "\n",
    "    padded_source = np.pad(source_image, ((padding, padding), (padding, padding)), mode='edge')\n",
    "    padded_source = np.array(padded_source, dtype=np.float64)\n",
    "\n",
    "    padded_target = np.pad(target_image, ((padding, padding), (padding, padding)), mode='edge')\n",
    "    padded_target = np.array(padded_target, dtype=np.float64)\n",
    "\n",
    "    # target_image = np.array(target_image, dtype=np.float64)\n",
    "\n",
    "    y1, x1, y2, x2 = target_swatch\n",
    "    y1 += padding\n",
    "    x1 += padding\n",
    "    y2 += padding\n",
    "    x2 += padding\n",
    "\n",
    "    source_patches = []\n",
    "\n",
    "    for color in colors:\n",
    "        s_y, s_x = int(color[3]), int(color[4])\n",
    "        s_y += padding\n",
    "        s_x += padding\n",
    "        source_patch = padded_source[s_y - padding:s_y + padding+1, s_x - padding:s_x + padding+1]\n",
    "        source_patches.append(source_patch)\n",
    "    source_patches = np.array(source_patches)\n",
    "\n",
    "    for y in range(y1, y2):\n",
    "        for x in range(x1, x2):\n",
    "            target_patch = padded_target[y - padding:y + padding+1, x - padding:x + padding+1]\n",
    "            min_ssd = np.inf\n",
    "\n",
    "            best_match_color = None\n",
    "\n",
    "            for color in range(len(colors)):\n",
    "                source_patch = source_patches[color]\n",
    "\n",
    "                ssd = compute_ssd_patch(source_patch, target_patch)\n",
    "                if ssd < min_ssd:\n",
    "                    min_ssd = ssd\n",
    "                    best_match_color = colors[color]\n",
    "            \n",
    "            target_color_image[y-padding, x-padding, 1], target_color_image[y-padding, x-padding, 2]  = best_match_color[1].copy(), best_match_color[2].copy()\n",
    "    return target_color_image\n",
    "\n",
    "target_image_bgr = cv2.imread(path + 'target_image2.jpg')\n",
    "target_img = cv2.cvtColor(target_image_bgr, cv2.COLOR_BGR2LAB)\n",
    "targte_image = target_img[:, :, 0]\n",
    "\n",
    "h, w = target_image.shape[0], target_image.shape[1]\n",
    "a, b = np.zeros((h, w)), np.zeros((h, w))\n",
    "\n",
    "target_swatch = [0, 0, h, w]\n",
    "target_image_to_color = np.dstack((target_image.copy(), a, b))\n",
    "colored_image_lab = coloring(source_image_linshift[:, :, 0], target_image.copy(), target_swatch, target_image_to_color, sampled_colors, sds, 5)\n",
    "\n",
    "colored_image_lab_uint = np.array(colored_image_lab, dtype=np.uint8)\n",
    "\n",
    "cv2.imwrite(path + 'colored_image_wo_swatch.jpg', cv2.cvtColor(colored_image_lab_uint, cv2.COLOR_LAB2BGR))\n",
    "cv2.imwrite('colored_image_wo_swatch.jpg', cv2.cvtColor(colored_image_lab_uint, cv2.COLOR_LAB2BGR))\n",
    "print('Target image with colors and without swatches generated\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
